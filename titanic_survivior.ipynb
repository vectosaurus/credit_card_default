{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survivor Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the data we will try to model the chances of a passenger surviving given his attributes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two data sets - `train.csv` and `test.csv`. We will build and assess our model on the train dataset and predict the outcomes for the final model for the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has nine feature variables and one target variable - `survival`. The `survival` variable takes two values -`0` and `1`, `1` implying that the passenger survived. z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `pclass` is for the ticket class and takes the values `1`, `2` and `3`. It serves as a proxy for the passenger's socio-economic status. Other feature variables are `sex` - gender of the passenger, `Age` - age in years of the passenger, `sibsp` - is the number of siblings/spouses aboard the Titanic, `parch` - is the number of parents/children aboard the Titanic, `ticket` - is the ticket number of the passenger, `fare` - is the passenger fare, `cabin` - is the cabin number of the passenger and `embarked` - is the port of embarkation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following sections we will check for outliers, missing values and duplicates. We will check if the dataset needs to be balanced before building the model by checking the event rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Missing Value Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shubhamgandhi/Desktop/discover\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "import pandas as pd\n",
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('../titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "# read the data and check the dimensions\n",
    "data = pd.read_csv('train.csv')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get number of missing values for each variable\n",
    "print(data.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three variables have missing values - `Age`, `cabin` and `Embarked`. We will drop the variable `cabin` as it denotes the cabin number of the passenger and doesn't represent any attribute of the passenger that can help predict his/her chance at survival. However, `Age` is an important variable. To impute the missing values in the `Age` column we will use nearest neighbors imputation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 11)\n"
     ]
    }
   ],
   "source": [
    "# drop the cabin variable\n",
    "data.drop(['Cabin'], inplace=True,axis=1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 8)\n"
     ]
    }
   ],
   "source": [
    "# drop passenger id, ticket number name of the passenger from the dataset\n",
    "data.drop(['PassengerId','Name','Ticket'], inplace=True,axis=1)\n",
    "print(data.shape)\n",
    "# rearrange the columns in the dataframe\n",
    "data = data.loc[:,['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked  Survived\n",
      "0       3    male  22.0      1      0   7.2500        S         0\n",
      "1       1  female  38.0      1      0  71.2833        C         1\n",
      "2       3  female  26.0      0      0   7.9250        S         1\n",
      "3       1  female  35.0      1      0  53.1000        S         1\n",
      "4       3    male  35.0      0      0   8.0500        S         0\n"
     ]
    }
   ],
   "source": [
    "# preview the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 13)\n"
     ]
    }
   ],
   "source": [
    "# knn requires all data to be numerical. We will convert Pclass, Sex and Embarked to dummy encoded variables\n",
    "dm_pclass = pd.get_dummies(data.loc[:,'Pclass'],prefix='Pclass')\n",
    "dm_sex = pd.get_dummies(data.loc[:,'Sex'],prefix='Sex')\n",
    "dm_embarked = pd.get_dummies(data.loc[:,'Embarked'],prefix='Embarked')\n",
    "\n",
    "data_ohe = pd.concat([data, dm_pclass, dm_sex, dm_embarked], axis=1)\n",
    "data_ohe.drop(['Pclass','Sex','Embarked'],inplace=True,axis=1)\n",
    "print(data_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  SibSp  Parch     Fare  Survived  Pclass_1  Pclass_2  Pclass_3  \\\n",
      "0  22.0      1      0   7.2500         0         0         0         1   \n",
      "1  38.0      1      0  71.2833         1         1         0         0   \n",
      "2  26.0      0      0   7.9250         1         0         0         1   \n",
      "3  35.0      1      0  53.1000         1         1         0         0   \n",
      "4  35.0      0      0   8.0500         0         0         0         1   \n",
      "\n",
      "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
      "0           0         1           0           0           1  \n",
      "1           1         0           1           0           0  \n",
      "2           1         0           0           0           1  \n",
      "3           1         0           0           0           1  \n",
      "4           0         1           0           0           1  \n"
     ]
    }
   ],
   "source": [
    "# preview data\n",
    "print(data_ohe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age           177\n",
      "SibSp           0\n",
      "Parch           0\n",
      "Fare            0\n",
      "Survived        0\n",
      "Pclass_1        0\n",
      "Pclass_2        0\n",
      "Pclass_3        0\n",
      "Sex_female      0\n",
      "Sex_male        0\n",
      "Embarked_C      0\n",
      "Embarked_Q      0\n",
      "Embarked_S      0\n",
      "dtype: int64\n",
      "[714 891 891 891 891 891 891 891 891 891 891 891 891]\n",
      "[891 891 891 891 891 891 891 891 891 891 891 891 891]\n",
      "(891, 13)\n"
     ]
    }
   ],
   "source": [
    "# get missing value information\n",
    "import numpy as np\n",
    "print(data_ohe.isnull().sum(axis=0))\n",
    "print(np.isfinite(data_ohe.values).sum(axis=0))\n",
    "print((np.isfinite(data_ohe.values) | np.isnan(data_ohe.values)).sum(axis=0))\n",
    "print(data_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SibSp', 'Parch', 'Fare', 'Survived', 'Pclass_1', 'Pclass_2',\n",
       "       'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q',\n",
       "       'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ohe.columns[1:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbor is a distance based method and hence it is important to scale the data before we use it for imputing the missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max=MinMaxScaler()\n",
    "data_ohe.loc[:,['SibSp', 'Parch', 'Fare']] = min_max.fit_transform(data_ohe.loc[:,['SibSp', 'Parch', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  SibSp  Parch      Fare  Survived  Pclass_1  Pclass_2  Pclass_3  \\\n",
      "0  22.0  0.125    0.0  0.014151         0         0         0         1   \n",
      "1  38.0  0.125    0.0  0.139136         1         1         0         0   \n",
      "2  26.0  0.000    0.0  0.015469         1         0         0         1   \n",
      "3  35.0  0.125    0.0  0.103644         1         1         0         0   \n",
      "4  35.0  0.000    0.0  0.015713         0         0         0         1   \n",
      "\n",
      "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
      "0           0         1           0           0           1  \n",
      "1           1         0           1           0           0  \n",
      "2           1         0           0           0           1  \n",
      "3           1         0           0           0           1  \n",
      "4           0         1           0           0           1  \n"
     ]
    }
   ],
   "source": [
    "# data_ohe = pd.to_numeric(data_ohe, errors='ignore')\n",
    "print(data_ohe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Age           float64\n",
      "SibSp         float64\n",
      "Parch         float64\n",
      "Fare          float64\n",
      "Survived        int64\n",
      "Pclass_1        uint8\n",
      "Pclass_2        uint8\n",
      "Pclass_3        uint8\n",
      "Sex_female      uint8\n",
      "Sex_male        uint8\n",
      "Embarked_C      uint8\n",
      "Embarked_Q      uint8\n",
      "Embarked_S      uint8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(type(data_ohe))\n",
    "print(data_ohe.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 13)\n",
      "Index(['Age', 'SibSp', 'Parch', 'Fare', 'Survived', 'Pclass_1', 'Pclass_2',\n",
      "       'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q',\n",
      "       'Embarked_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_ohe.shape)\n",
    "print(data_ohe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'SibSp', 'Parch', 'Fare', 'Survived', 'Pclass_1', 'Pclass_2',\n",
      "       'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q',\n",
      "       'Embarked_S'],\n",
      "      dtype='object')\n",
      "Fitting 3 folds for each of 336 candidates, totalling 1008 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1008 out of 1008 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "          weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [5, 8, 10, 12, 15, 20, 25], 'weights': ['uniform', 'distance'], 'algorithm': ['ball_tree', 'kd_tree', 'brute'], 'leaf_size': [10, 15, 20, 25, 30, 35, 40, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an instance of the K Nearest Neigbhors object\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "imputer = KNeighborsRegressor(n_neighbors=5, weights='uniform', algorithm='auto', \n",
    "                              leaf_size=30, p=2, metric='minkowski', metric_params=None, \n",
    "                              n_jobs=-1)\n",
    "param_grid = {\n",
    "    'n_neighbors': [5,8,10,12,15,20,25],\n",
    "    'weights':['uniform', 'distance'],\n",
    "    'algorithm': ['ball_tree', 'kd_tree', 'brute'],\\\n",
    "    'leaf_size':[10,15,20,25,30,35,40,50]\n",
    "}\n",
    "print(data_ohe.columns)\n",
    "imputer_cv = GridSearchCV(imputer,param_grid, cv=3,verbose=True)\n",
    "imputer_cv.fit(data_ohe.loc[~data_ohe.isnull().any(axis=1),['SibSp', 'Parch', 'Fare', 'Survived', 'Pclass_1', \n",
    "                                                            'Pclass_2','Pclass_3', 'Sex_female', 'Sex_male', \n",
    "                                                            'Embarked_C', 'Embarked_Q','Embarked_S']],\n",
    "               data_ohe.loc[~data_ohe.isnull().any(axis=1),'Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ohe.loc[~data_ohe.isnull().any(axis=1),['SibSp', 'Parch', 'Fare', 'Survived', 'Pclass_1', \n",
    "                                                            'Pclass_2','Pclass_3', 'Sex_female', 'Sex_male', \n",
    "                                                            'Embarked_C', 'Embarked_Q','Embarked_S']].shape\n",
    "data_ohe.loc[~data_ohe.isnull().any(axis=1),'Age'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 0.00210738,  0.00209554,  0.00227523,  0.00214203,  0.00217048,\n",
      "        0.00225592,  0.00213019,  0.0017008 ,  0.00186674,  0.00192761,\n",
      "        0.00213401,  0.00233928,  0.00209506,  0.00216873,  0.002316  ,\n",
      "        0.00234779,  0.00238856,  0.00235136,  0.00217756,  0.00233579,\n",
      "        0.00239213,  0.00225663,  0.0023547 ,  0.00233777,  0.00236996,\n",
      "        0.00233849,  0.00231282,  0.00233841,  0.00235025,  0.00236225,\n",
      "        0.00237171,  0.00241264,  0.00235168,  0.00227912,  0.00236535,\n",
      "        0.00222921,  0.00225465,  0.00234063,  0.00235271,  0.00234739,\n",
      "        0.00233571,  0.00233547,  0.00235987,  0.00235836,  0.00236138,\n",
      "        0.00236098,  0.00236662,  0.00235637,  0.00237099,  0.00235796,\n",
      "        0.00208934,  0.00235303,  0.00234938,  0.00232927,  0.00234199,\n",
      "        0.00228588,  0.00196362,  0.0029223 ,  0.00196473,  0.00225806,\n",
      "        0.00235446,  0.00231004,  0.00232236,  0.00223001,  0.00227022,\n",
      "        0.00217628,  0.00205533,  0.00228834,  0.00231735,  0.00228707,\n",
      "        0.00231663,  0.00225465,  0.00234898,  0.00232331,  0.00235279,\n",
      "        0.00232466,  0.00235359,  0.00229796,  0.00233467,  0.00231671,\n",
      "        0.00232172,  0.002304  ,  0.00229438,  0.00228532,  0.00232601,\n",
      "        0.00232585,  0.00231703,  0.00225488,  0.00232331,  0.00231393,\n",
      "        0.00233674,  0.00232347,  0.00201289,  0.00231202,  0.00228532,\n",
      "        0.00229112,  0.00231576,  0.00222937,  0.0023369 ,  0.00220084,\n",
      "        0.00231735,  0.00234421,  0.00233682,  0.00231798,  0.00233531,\n",
      "        0.00231457,  0.00148296,  0.00199366,  0.00203602,  0.00229208,\n",
      "        0.00222333,  0.00233881,  0.00244347,  0.00209824,  0.00244268,\n",
      "        0.00242766,  0.00242432,  0.0024097 ,  0.00242861,  0.00209324,\n",
      "        0.00210357,  0.0024093 ,  0.00211469,  0.00198793,  0.00179625,\n",
      "        0.00207965,  0.00185927,  0.00176573,  0.00238109,  0.00237997,\n",
      "        0.00240533,  0.00236622,  0.00238864,  0.00238474,  0.00240461,\n",
      "        0.0023791 ,  0.00237918,  0.00236297,  0.0023756 ,  0.00236932,\n",
      "        0.00238776,  0.00239833,  0.00239523,  0.00239555,  0.00239539,\n",
      "        0.00219576,  0.00240461,  0.00215125,  0.0023946 ,  0.00236265,\n",
      "        0.0024027 ,  0.00233873,  0.00237719,  0.00237139,  0.00235184,\n",
      "        0.00225639,  0.00236869,  0.00240843,  0.00238705,  0.00238601,\n",
      "        0.00239499,  0.00240199,  0.00239952,  0.00238339,  0.00238419,\n",
      "        0.00230169,  0.00238784,  0.00235478,  0.00230734,  0.00234588,\n",
      "        0.00235685,  0.00236098,  0.00234628,  0.00231695,  0.00235359,\n",
      "        0.00232832,  0.00236766,  0.00234397,  0.00234397,  0.00227499,\n",
      "        0.00231759,  0.00230376,  0.00230829,  0.00235065,  0.00235542,\n",
      "        0.00234834,  0.00233229,  0.00232466,  0.00223231,  0.00234874,\n",
      "        0.00235502,  0.00233221,  0.00234389,  0.00229669,  0.00232689,\n",
      "        0.0023156 ,  0.00234493,  0.0023454 ,  0.00232013,  0.00233865,\n",
      "        0.00235041,  0.00234397,  0.00234771,  0.00233308,  0.00236392,\n",
      "        0.00231838,  0.00229589,  0.00228532,  0.00233467,  0.0023334 ,\n",
      "        0.00234103,  0.00233936,  0.00237425,  0.00235661,  0.00235899,\n",
      "        0.00233213,  0.00230702,  0.00233682,  0.0023303 ,  0.00233078,\n",
      "        0.0023334 ,  0.00231624,  0.0023373 ,  0.00226967,  0.00173108,\n",
      "        0.00162903,  0.00169158,  0.00153025,  0.0015626 ,  0.00153979,\n",
      "        0.00154964,  0.00153303,  0.0015653 ,  0.00159192,  0.00158262,\n",
      "        0.00178695,  0.0015711 ,  0.0015343 ,  0.00155799,  0.00152596,\n",
      "        0.00165868,  0.00163182,  0.00165987,  0.00152985,  0.00166734,\n",
      "        0.00152588,  0.00156061,  0.00156029,  0.00161258,  0.00153343,\n",
      "        0.00154805,  0.0015893 ,  0.00155942,  0.00158413,  0.00158254,\n",
      "        0.00154201,  0.00156895,  0.00151817,  0.00155465,  0.00155695,\n",
      "        0.00155441,  0.00155775,  0.00155187,  0.00152206,  0.00160336,\n",
      "        0.00155727,  0.00155393,  0.00155958,  0.00154901,  0.00152135,\n",
      "        0.00155902,  0.00151428,  0.00157905,  0.00154432,  0.00155759,\n",
      "        0.00152222,  0.00161235,  0.00154813,  0.00157301,  0.00154996,\n",
      "        0.00153542,  0.00154352,  0.00156538,  0.001544  ,  0.00158167,\n",
      "        0.00153303,  0.00156434,  0.00154106,  0.00159232,  0.00153852,\n",
      "        0.00159756,  0.00157158,  0.00162164,  0.00157682,  0.0015858 ,\n",
      "        0.00154018,  0.00156371,  0.00154726,  0.00157666,  0.00154106,\n",
      "        0.00158668,  0.001532  ,  0.00155576,  0.00155727,  0.00156228,\n",
      "        0.00155091,  0.00156426,  0.00151078,  0.00157595,  0.00152802,\n",
      "        0.00155997,  0.00150935,  0.00156132,  0.00154392,  0.00157666,\n",
      "        0.00158532,  0.00160432,  0.00159033,  0.0015831 ,  0.00158397,\n",
      "        0.00157801,  0.00155314,  0.00157928,  0.00152834,  0.00157928,\n",
      "        0.00152771,  0.00154845,  0.00159097,  0.00155512,  0.0015494 ,\n",
      "        0.00155958,  0.00156061,  0.00156705,  0.0015823 ,  0.00156569,\n",
      "        0.00152524]), 'std_fit_time': array([  1.86000417e-04,   4.24170008e-04,   2.00417537e-04,\n",
      "         4.48063952e-04,   3.66753927e-04,   1.48503965e-04,\n",
      "         3.31893297e-04,   1.96887109e-04,   4.11876742e-04,\n",
      "         2.77627012e-04,   3.83766548e-04,   5.48816346e-05,\n",
      "         1.70399115e-04,   1.40377643e-04,   4.52681483e-05,\n",
      "         7.05531922e-05,   1.96531096e-05,   3.99464778e-05,\n",
      "         2.78577960e-04,   5.07258523e-05,   5.57666215e-05,\n",
      "         1.80630149e-04,   2.81174483e-05,   5.36522447e-05,\n",
      "         3.84607589e-05,   4.25990837e-05,   6.71405044e-05,\n",
      "         6.92336793e-05,   3.62816018e-05,   5.29883169e-05,\n",
      "         1.67553970e-05,   1.48388365e-04,   3.73485239e-05,\n",
      "         1.31740642e-04,   4.53300541e-05,   1.79632327e-04,\n",
      "         1.96056855e-04,   5.33952353e-05,   2.07656971e-05,\n",
      "         5.54039272e-05,   1.88057036e-05,   6.46128523e-05,\n",
      "         2.71762321e-05,   5.46550289e-05,   3.34949585e-05,\n",
      "         5.59348934e-05,   3.69301751e-05,   5.99581514e-05,\n",
      "         2.98003090e-05,   5.69406263e-05,   4.23261603e-04,\n",
      "         5.40617596e-05,   3.58648962e-05,   5.07200000e-05,\n",
      "         2.36919778e-05,   2.22980508e-05,   2.53585106e-04,\n",
      "         1.73453756e-03,   3.97130277e-04,   5.00853069e-05,\n",
      "         3.42584260e-05,   5.96850171e-05,   2.55729783e-05,\n",
      "         4.24859559e-05,   1.16464975e-04,   1.38224529e-04,\n",
      "         3.69997282e-04,   5.83325376e-05,   3.22587376e-05,\n",
      "         6.84833822e-05,   5.38809578e-05,   4.16936467e-05,\n",
      "         3.25283881e-05,   4.70131507e-05,   2.43998505e-05,\n",
      "         4.76082894e-05,   2.73619874e-05,   6.67360060e-05,\n",
      "         2.65329875e-05,   5.87510338e-05,   2.68352441e-05,\n",
      "         4.70477987e-05,   4.48300196e-06,   5.58701552e-05,\n",
      "         3.67525675e-05,   5.31854561e-05,   3.82810132e-05,\n",
      "         9.81818272e-05,   2.28768670e-05,   4.60932995e-05,\n",
      "         3.23711211e-05,   6.55214087e-05,   4.25809189e-04,\n",
      "         6.11760373e-05,   5.17938717e-05,   5.22908468e-05,\n",
      "         2.78905582e-05,   1.38475341e-04,   4.16686442e-05,\n",
      "         2.07170335e-04,   2.16548595e-05,   5.11977954e-05,\n",
      "         4.32602539e-05,   5.02323799e-05,   2.36239007e-05,\n",
      "         3.32625962e-05,   7.92112017e-05,   4.15591008e-04,\n",
      "         4.56995839e-04,   5.64383775e-05,   1.01221783e-04,\n",
      "         3.73703324e-05,   2.85348517e-05,   4.32297717e-04,\n",
      "         3.22287678e-05,   4.58773904e-05,   2.90729492e-05,\n",
      "         6.21984678e-05,   2.62132768e-05,   4.21777688e-04,\n",
      "         4.69473850e-04,   6.19663092e-05,   3.95691258e-04,\n",
      "         3.80478555e-04,   4.11410723e-04,   4.12910067e-04,\n",
      "         3.80331882e-04,   3.82803483e-04,   3.90366286e-05,\n",
      "         2.33555578e-05,   3.09083019e-05,   5.02908124e-05,\n",
      "         2.88117342e-05,   6.20210189e-05,   3.92830736e-05,\n",
      "         4.50437979e-05,   1.87407721e-05,   4.08807340e-05,\n",
      "         3.64481631e-05,   7.15124153e-05,   5.40072903e-05,\n",
      "         6.53415781e-05,   2.31133529e-05,   4.18139033e-05,\n",
      "         3.14501730e-05,   2.37919709e-04,   3.39673733e-05,\n",
      "         2.52364987e-04,   2.19244289e-05,   5.23676096e-05,\n",
      "         3.21681555e-05,   6.48362170e-05,   2.76684279e-05,\n",
      "         5.07648094e-05,   6.61499737e-05,   2.19852786e-04,\n",
      "         7.98416324e-05,   3.87483781e-05,   2.86161893e-05,\n",
      "         3.99018659e-05,   4.00989211e-05,   8.28723989e-05,\n",
      "         4.36201037e-05,   5.37235356e-05,   2.84088518e-05,\n",
      "         1.26481599e-04,   1.43900750e-05,   6.53952025e-05,\n",
      "         7.10016062e-05,   4.99149033e-05,   2.50315539e-05,\n",
      "         5.01005631e-05,   2.07163658e-05,   6.07167447e-05,\n",
      "         2.62941094e-05,   5.80163851e-05,   3.52732389e-05,\n",
      "         7.68315560e-05,   2.31845638e-05,   1.10493744e-04,\n",
      "         1.26554135e-05,   5.49971712e-05,   6.78228108e-05,\n",
      "         5.15985154e-05,   1.91590588e-05,   6.33650422e-05,\n",
      "         4.15160316e-05,   6.83543290e-05,   1.67989309e-04,\n",
      "         6.84335622e-05,   2.74594544e-05,   5.31596804e-05,\n",
      "         1.26444292e-05,   6.74998326e-05,   3.48256201e-05,\n",
      "         6.75086275e-05,   2.63229180e-05,   5.36070212e-05,\n",
      "         7.45556241e-05,   4.96998383e-05,   2.58442025e-05,\n",
      "         5.55514721e-05,   3.60587904e-05,   6.80058320e-05,\n",
      "         2.46760350e-05,   4.57030444e-05,   9.24150791e-05,\n",
      "         6.94984592e-05,   3.40598462e-05,   5.19515488e-05,\n",
      "         3.27528472e-05,   5.55840930e-05,   4.40781442e-05,\n",
      "         4.16813746e-05,   4.19139289e-05,   4.73268720e-05,\n",
      "         3.58465767e-05,   6.35173625e-05,   2.33998655e-05,\n",
      "         4.96139840e-05,   2.81542631e-05,   5.51168204e-05,\n",
      "         2.22308190e-05,   3.96579922e-05,   1.46705306e-04,\n",
      "         1.65464250e-04,   2.28159563e-04,   1.00255572e-05,\n",
      "         3.82070267e-05,   2.51877566e-05,   1.03966783e-05,\n",
      "         2.12286275e-05,   5.69902974e-05,   5.89130331e-05,\n",
      "         4.85699473e-05,   3.05782958e-04,   3.40331329e-05,\n",
      "         4.57491783e-05,   4.15671167e-05,   2.53070837e-05,\n",
      "         1.48197557e-04,   1.40419210e-04,   1.49636611e-04,\n",
      "         1.59821482e-05,   6.79272157e-05,   2.90857638e-05,\n",
      "         2.61046267e-05,   5.31519572e-05,   5.04698338e-05,\n",
      "         5.03781460e-05,   5.17110057e-05,   7.91147429e-05,\n",
      "         5.13592703e-05,   3.43589400e-05,   8.67390107e-05,\n",
      "         3.38880698e-05,   4.68702602e-05,   2.00558386e-05,\n",
      "         5.76415506e-05,   1.18241087e-05,   1.39515052e-05,\n",
      "         4.02554942e-05,   3.17666849e-05,   2.80585344e-05,\n",
      "         2.03825808e-05,   3.50003743e-05,   3.04805097e-05,\n",
      "         2.82914451e-05,   3.52123068e-05,   2.56260233e-05,\n",
      "         5.72644833e-05,   2.82988112e-05,   1.34461878e-05,\n",
      "         1.27032338e-05,   2.18834836e-05,   2.69038814e-05,\n",
      "         7.07773527e-05,   3.18544432e-05,   3.52909612e-05,\n",
      "         3.26073182e-05,   3.35896721e-05,   2.32243031e-05,\n",
      "         4.47890029e-05,   3.05796033e-05,   3.28204629e-05,\n",
      "         2.27320165e-05,   4.20159713e-05,   3.09921737e-05,\n",
      "         5.39256002e-05,   2.55119020e-05,   7.47018672e-05,\n",
      "         5.08505837e-05,   3.85178642e-05,   8.63881317e-06,\n",
      "         6.33844759e-05,   2.53068341e-05,   4.92522749e-05,\n",
      "         1.86935303e-05,   6.40679418e-05,   2.51071355e-05,\n",
      "         1.40214991e-05,   1.22475902e-05,   1.84414712e-05,\n",
      "         5.36261045e-05,   1.96993326e-05,   5.27560932e-05,\n",
      "         3.32033005e-05,   3.19287097e-05,   4.58437867e-05,\n",
      "         3.46754941e-05,   5.31243819e-05,   2.69580562e-05,\n",
      "         3.39707201e-05,   3.30484808e-05,   3.30431292e-05,\n",
      "         7.68867779e-05,   6.47597997e-05,   6.22122764e-05,\n",
      "         2.35226240e-05,   1.13782268e-05,   4.26950511e-05,\n",
      "         3.45552527e-05,   1.50839404e-05,   1.76196904e-05,\n",
      "         3.04355114e-05,   1.42538069e-05,   3.00169738e-05,\n",
      "         1.07693613e-04,   4.38345956e-05,   1.95874402e-05,\n",
      "         2.42252779e-05,   3.02890660e-05,   3.29399425e-05,\n",
      "         4.73588900e-05,   3.16160177e-05,   1.14048399e-05]), 'mean_score_time': array([ 0.10584744,  0.10581978,  0.10417008,  0.10500964,  0.10772999,\n",
      "        0.10868947,  0.10451516,  0.10368061,  0.10462459,  0.10430996,\n",
      "        0.10778705,  0.10757899,  0.10657128,  0.10676424,  0.1084187 ,\n",
      "        0.10583933,  0.10705002,  0.10814603,  0.10703969,  0.10718234,\n",
      "        0.10631037,  0.1080877 ,  0.10748458,  0.10895602,  0.10855802,\n",
      "        0.1072739 ,  0.10686064,  0.10708865,  0.10849539,  0.10870266,\n",
      "        0.10758162,  0.10679364,  0.10788369,  0.10690292,  0.10833534,\n",
      "        0.10862843,  0.10534604,  0.10871768,  0.10844254,  0.10665758,\n",
      "        0.10856994,  0.10879024,  0.10800441,  0.10788528,  0.10859243,\n",
      "        0.10605129,  0.10647504,  0.10829624,  0.10811067,  0.10837038,\n",
      "        0.10414004,  0.10870361,  0.10800624,  0.1083347 ,  0.10523303,\n",
      "        0.10393476,  0.10736736,  0.10662397,  0.10750683,  0.10558661,\n",
      "        0.10857304,  0.10734797,  0.10698803,  0.10867325,  0.10480142,\n",
      "        0.107728  ,  0.10621476,  0.10877077,  0.10824267,  0.10887647,\n",
      "        0.10665003,  0.10782003,  0.10765815,  0.10694663,  0.10854594,\n",
      "        0.10696697,  0.10858933,  0.10833104,  0.1086034 ,  0.10694043,\n",
      "        0.10849937,  0.10845264,  0.10518638,  0.10875575,  0.10770718,\n",
      "        0.10828908,  0.10841505,  0.10873572,  0.10855603,  0.10754871,\n",
      "        0.10781598,  0.10869177,  0.10835075,  0.10872602,  0.10860634,\n",
      "        0.10718083,  0.10855746,  0.10873501,  0.10848721,  0.10783696,\n",
      "        0.10850636,  0.10845288,  0.10695593,  0.10817949,  0.10856613,\n",
      "        0.1086398 ,  0.10528906,  0.10669359,  0.1065534 ,  0.10741552,\n",
      "        0.10427165,  0.10877403,  0.10510977,  0.10602681,  0.10845359,\n",
      "        0.10811591,  0.10856565,  0.10581168,  0.10560481,  0.10578068,\n",
      "        0.10607743,  0.10689727,  0.10822845,  0.10722343,  0.10826715,\n",
      "        0.10580262,  0.10485458,  0.10719538,  0.10848912,  0.10698104,\n",
      "        0.10782743,  0.10871975,  0.10852798,  0.10647829,  0.10682543,\n",
      "        0.10827239,  0.10855484,  0.10819308,  0.10860451,  0.10877037,\n",
      "        0.10836466,  0.10867262,  0.10598675,  0.10719705,  0.10761126,\n",
      "        0.10711098,  0.10816836,  0.10642187,  0.10772912,  0.106649  ,\n",
      "        0.1085426 ,  0.10875964,  0.10831555,  0.10765481,  0.10722836,\n",
      "        0.10730338,  0.10699161,  0.10870234,  0.107361  ,  0.1075    ,\n",
      "        0.10853306,  0.10807443,  0.1085856 ,  0.10877172,  0.10737832,\n",
      "        0.10871768,  0.10837754,  0.10794091,  0.10855301,  0.108682  ,\n",
      "        0.10546239,  0.1088384 ,  0.10594908,  0.10871474,  0.10829711,\n",
      "        0.10714181,  0.10843825,  0.10602053,  0.10702634,  0.107512  ,\n",
      "        0.1067942 ,  0.10780636,  0.10796388,  0.10866515,  0.10772896,\n",
      "        0.10873969,  0.10693566,  0.10708229,  0.10837301,  0.10780358,\n",
      "        0.10867031,  0.10717368,  0.1085608 ,  0.10853068,  0.10678299,\n",
      "        0.10883307,  0.10852154,  0.10873985,  0.10850716,  0.10873063,\n",
      "        0.10659027,  0.10783132,  0.10689068,  0.10699892,  0.10859497,\n",
      "        0.1080277 ,  0.10859179,  0.10698565,  0.10859823,  0.107023  ,\n",
      "        0.10855691,  0.10797429,  0.10852464,  0.1086847 ,  0.10662397,\n",
      "        0.1087563 ,  0.10717003,  0.10870926,  0.10737594,  0.10874764,\n",
      "        0.10788067,  0.10872873,  0.10661403,  0.10748768,  0.17312423,\n",
      "        0.1746339 ,  0.17152278,  0.17070301,  0.16851751,  0.17385999,\n",
      "        0.17216976,  0.16957736,  0.17497015,  0.17258962,  0.17278282,\n",
      "        0.17064293,  0.17432237,  0.17286396,  0.1713411 ,  0.172683  ,\n",
      "        0.17262769,  0.1748836 ,  0.17396021,  0.17328787,  0.17117198,\n",
      "        0.17145705,  0.17125368,  0.17234914,  0.17481478,  0.17160924,\n",
      "        0.17334199,  0.17621104,  0.17561666,  0.17353924,  0.17173044,\n",
      "        0.1722846 ,  0.1711026 ,  0.17117993,  0.17202989,  0.17704431,\n",
      "        0.16946872,  0.17676202,  0.17157578,  0.17133029,  0.17273966,\n",
      "        0.1742382 ,  0.17321396,  0.17127713,  0.17244109,  0.17167234,\n",
      "        0.17409293,  0.17046118,  0.17278759,  0.17355378,  0.17047429,\n",
      "        0.17205691,  0.17095065,  0.17029492,  0.17468468,  0.17338292,\n",
      "        0.17059795,  0.17485857,  0.1715676 ,  0.17431831,  0.1732707 ,\n",
      "        0.17659434,  0.16733766,  0.17489266,  0.17285132,  0.17262872,\n",
      "        0.17193206,  0.17211103,  0.17158397,  0.17344634,  0.17092609,\n",
      "        0.17423193,  0.17153438,  0.17300948,  0.17401886,  0.17259264,\n",
      "        0.17304738,  0.17421691,  0.17231393,  0.17454664,  0.17330154,\n",
      "        0.17478077,  0.17165963,  0.17405065,  0.1703763 ,  0.17000198,\n",
      "        0.17396188,  0.17490133,  0.17324392,  0.17319592,  0.17227817,\n",
      "        0.17163197,  0.17726668,  0.17934672,  0.17529488,  0.17852585,\n",
      "        0.17180928,  0.17589037,  0.17510494,  0.17204801,  0.17331274,\n",
      "        0.17597222,  0.17529917,  0.17841331,  0.17051291,  0.17781496,\n",
      "        0.1739471 ,  0.17004863,  0.16998355,  0.17413545,  0.17050997,\n",
      "        0.17343434]), 'std_score_time': array([  9.10794346e-04,   2.18264477e-03,   4.65550520e-04,\n",
      "         1.58611410e-03,   1.08544908e-03,   6.04933084e-05,\n",
      "         2.25256814e-03,   6.85314068e-04,   8.13012024e-04,\n",
      "         5.17641614e-04,   1.04430459e-03,   1.77071824e-03,\n",
      "         1.63779315e-03,   2.56645669e-03,   1.43543562e-04,\n",
      "         2.24686344e-03,   2.04673112e-03,   8.31059918e-04,\n",
      "         1.69863131e-03,   1.23486028e-03,   2.10073456e-03,\n",
      "         8.96079545e-04,   1.51444436e-03,   3.09408552e-04,\n",
      "         3.44520117e-05,   2.05302003e-03,   2.47641509e-03,\n",
      "         2.43849592e-03,   9.81428361e-05,   4.80048966e-05,\n",
      "         6.91318039e-04,   1.45383170e-03,   8.79373912e-04,\n",
      "         2.11628443e-03,   3.64872631e-04,   9.62196131e-05,\n",
      "         2.28285604e-03,   1.59378258e-05,   8.72529483e-05,\n",
      "         1.88383856e-03,   2.53848307e-05,   5.21017183e-05,\n",
      "         6.89747225e-04,   1.17921952e-03,   5.81520895e-05,\n",
      "         2.01350835e-03,   1.81106462e-03,   3.97891601e-04,\n",
      "         6.71788450e-04,   4.28589713e-04,   1.19702508e-03,\n",
      "         3.38610345e-05,   7.52587446e-04,   5.42989240e-04,\n",
      "         1.22143378e-03,   1.08723311e-03,   1.59309030e-03,\n",
      "         2.52200721e-03,   4.62502397e-04,   1.72903873e-03,\n",
      "         1.51006799e-05,   2.01056970e-03,   2.20978883e-03,\n",
      "         3.67243732e-05,   1.67828585e-03,   1.43979720e-03,\n",
      "         2.16187916e-03,   6.88432242e-05,   4.77051382e-04,\n",
      "         3.85565427e-05,   2.15843975e-03,   1.20776913e-03,\n",
      "         1.55713801e-03,   9.08059851e-04,   8.53066281e-06,\n",
      "         2.40849165e-03,   6.56537218e-05,   5.35509760e-04,\n",
      "         8.20578732e-05,   2.12929155e-03,   6.00026933e-05,\n",
      "         4.24055100e-04,   2.42617503e-03,   1.67791280e-05,\n",
      "         1.16720825e-03,   6.15994048e-04,   2.56705063e-04,\n",
      "         7.50785956e-05,   6.13204057e-05,   1.70471176e-03,\n",
      "         1.15202339e-03,   1.13948673e-05,   2.68125270e-04,\n",
      "         1.49628633e-05,   5.26802562e-05,   2.24779896e-03,\n",
      "         1.25300249e-05,   7.63856152e-05,   9.32076049e-05,\n",
      "         1.27118993e-03,   2.11931931e-05,   3.47948608e-04,\n",
      "         2.33412216e-03,   7.05156723e-04,   3.86063087e-05,\n",
      "         8.63550060e-05,   1.79480300e-03,   2.72188097e-03,\n",
      "         2.50002347e-03,   1.93138489e-03,   7.34144220e-04,\n",
      "         2.19054075e-05,   1.64756129e-03,   1.56509053e-03,\n",
      "         7.79100781e-05,   7.99894676e-04,   2.96881928e-05,\n",
      "         2.02811436e-03,   2.18522841e-03,   1.81228635e-03,\n",
      "         1.78021356e-03,   2.62302750e-03,   3.35708486e-04,\n",
      "         1.14951528e-03,   2.39646794e-04,   2.56401214e-03,\n",
      "         1.72956176e-03,   1.99200657e-03,   4.55940167e-05,\n",
      "         2.40450640e-03,   9.31123261e-04,   2.49116676e-05,\n",
      "         5.31597992e-05,   1.77007371e-03,   2.43921896e-03,\n",
      "         7.06951501e-04,   2.22535360e-05,   7.41752101e-04,\n",
      "         6.15869028e-05,   5.14420890e-05,   2.88347884e-04,\n",
      "         4.00789125e-05,   2.09081107e-03,   1.98540994e-03,\n",
      "         8.74133519e-04,   2.23941694e-03,   5.18701998e-04,\n",
      "         1.59955130e-03,   6.06521568e-04,   1.59638915e-03,\n",
      "         4.75844038e-05,   7.69962826e-05,   4.13549349e-04,\n",
      "         1.59957519e-03,   1.98145607e-03,   1.98975125e-03,\n",
      "         2.25472155e-03,   1.71322547e-05,   1.70985287e-03,\n",
      "         1.70996431e-03,   2.84830108e-05,   9.84520532e-04,\n",
      "         1.60160982e-05,   8.96600391e-06,   1.72492167e-03,\n",
      "         1.69271594e-05,   2.27180950e-04,   1.25580859e-03,\n",
      "         3.66479336e-05,   1.54222403e-05,   1.23655016e-03,\n",
      "         1.42551361e-05,   1.93027067e-03,   3.55498722e-05,\n",
      "         4.46495600e-04,   2.23221248e-03,   1.38700337e-04,\n",
      "         1.96389622e-03,   2.15480430e-03,   1.61816154e-03,\n",
      "         2.35885678e-03,   1.37426852e-03,   7.33452056e-04,\n",
      "         1.18513194e-05,   5.48791303e-04,   7.03789498e-05,\n",
      "         2.26935837e-03,   1.14927190e-03,   3.26723839e-04,\n",
      "         1.26744124e-03,   8.28495319e-05,   1.77691690e-03,\n",
      "         2.00536341e-05,   2.96151856e-04,   1.65728217e-03,\n",
      "         8.49245506e-05,   2.36794450e-05,   4.68130898e-05,\n",
      "         7.75284529e-05,   4.37003905e-05,   1.50455684e-03,\n",
      "         1.31916075e-03,   2.26822410e-03,   1.95834359e-03,\n",
      "         6.30286419e-05,   1.00883870e-03,   5.30086953e-05,\n",
      "         2.19027529e-03,   1.54218308e-05,   1.84423490e-03,\n",
      "         5.71523146e-05,   9.71097809e-04,   2.75483243e-05,\n",
      "         2.81026191e-05,   1.80497574e-03,   5.09952019e-05,\n",
      "         1.65343441e-03,   1.53112668e-05,   1.73533106e-03,\n",
      "         4.34481838e-05,   1.03083050e-03,   8.58821832e-06,\n",
      "         1.46179848e-03,   1.81722780e-03,   1.08580579e-03,\n",
      "         6.88778519e-03,   4.89912079e-04,   6.64410209e-04,\n",
      "         3.10982604e-03,   4.65327253e-03,   3.41957017e-03,\n",
      "         1.13923135e-03,   2.35941776e-03,   2.28117206e-03,\n",
      "         1.71360853e-03,   2.32070714e-03,   2.86413652e-03,\n",
      "         8.14937187e-04,   2.44078417e-03,   1.45587377e-03,\n",
      "         2.64751860e-03,   2.17322039e-03,   5.73836004e-03,\n",
      "         6.63842689e-03,   1.02703906e-03,   1.32649705e-03,\n",
      "         4.65740082e-03,   2.54199152e-03,   1.94003401e-03,\n",
      "         1.10460701e-03,   2.88518244e-03,   6.54740260e-04,\n",
      "         2.70704617e-03,   1.02000366e-03,   5.88937529e-04,\n",
      "         2.18711499e-03,   1.35805232e-03,   6.99944713e-04,\n",
      "         1.20314552e-03,   3.46526427e-03,   2.48002831e-03,\n",
      "         4.37263535e-03,   1.62067473e-04,   3.36412267e-04,\n",
      "         3.80920822e-03,   8.53038909e-04,   2.48751600e-03,\n",
      "         4.21761099e-03,   1.92389644e-03,   4.72909046e-04,\n",
      "         2.67037681e-03,   7.26723608e-04,   4.03392791e-04,\n",
      "         3.43651184e-03,   1.98304843e-03,   6.57017267e-04,\n",
      "         3.54159384e-04,   3.33941098e-03,   2.13671727e-03,\n",
      "         2.00491658e-03,   1.40077572e-03,   2.28303699e-03,\n",
      "         2.69391502e-03,   3.68328347e-03,   1.47510507e-03,\n",
      "         4.68141917e-03,   4.31995912e-04,   4.43705138e-03,\n",
      "         8.92789963e-04,   1.85246521e-03,   3.51750832e-03,\n",
      "         3.13087490e-03,   3.20274162e-03,   3.43290351e-03,\n",
      "         9.47534126e-04,   2.96044127e-03,   4.79153346e-04,\n",
      "         1.66490358e-03,   3.14698229e-03,   3.43999560e-03,\n",
      "         3.74880893e-03,   3.54826832e-03,   3.39651569e-04,\n",
      "         2.47899543e-03,   2.43659916e-03,   5.24106270e-03,\n",
      "         8.51945468e-04,   2.68554580e-03,   3.72313270e-03,\n",
      "         3.51713528e-03,   2.30936810e-03,   2.10273010e-03,\n",
      "         1.28451417e-03,   2.21072460e-03,   6.82860307e-04,\n",
      "         4.94798331e-03,   4.49217487e-03,   5.09832032e-03,\n",
      "         4.20822105e-03,   2.45482687e-03,   3.51451708e-03,\n",
      "         2.29835804e-03,   1.64745589e-03,   2.57393667e-03,\n",
      "         2.12100315e-03,   3.06945417e-03,   4.51786941e-03,\n",
      "         1.44645548e-03,   1.57518709e-03,   3.31172303e-04,\n",
      "         3.01175307e-03,   3.45468562e-03,   3.02357231e-03,\n",
      "         2.05290932e-03,   2.63803065e-03,   9.65641993e-04]), 'param_algorithm': masked_array(data = ['ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree'\n",
      " 'ball_tree' 'ball_tree' 'ball_tree' 'ball_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree'\n",
      " 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'kd_tree' 'brute' 'brute' 'brute'\n",
      " 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute'\n",
      " 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute'\n",
      " 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute'\n",
      " 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute'\n",
      " 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute'\n",
      " 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute'\n",
      " 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute'\n",
      " 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute'\n",
      " 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute'\n",
      " 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute'\n",
      " 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute'\n",
      " 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute' 'brute'\n",
      " 'brute'],\n",
      "             mask = [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'param_leaf_size': masked_array(data = [10 10 10 10 10 10 10 10 10 10 10 10 10 10 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 20 20 20 20 20 20 20 20 20 20 20 20 20 20 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 25 30 30 30 30 30 30 30 30 30 30 30 30 30 30 35 35 35 35 35\n",
      " 35 35 35 35 35 35 35 35 35 40 40 40 40 40 40 40 40 40 40 40 40 40 40 50 50\n",
      " 50 50 50 50 50 50 50 50 50 50 50 50 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 15 15 15 15 15 15 15 15 15 15 15 15 15 15 20 20 20 20 20 20 20 20 20 20\n",
      " 20 20 20 20 25 25 25 25 25 25 25 25 25 25 25 25 25 25 30 30 30 30 30 30 30\n",
      " 30 30 30 30 30 30 30 35 35 35 35 35 35 35 35 35 35 35 35 35 35 40 40 40 40\n",
      " 40 40 40 40 40 40 40 40 40 40 50 50 50 50 50 50 50 50 50 50 50 50 50 50 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 20 20 20 20 20 20 20 20 20 20 20 20 20 20 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 25 25 30 30 30 30 30 30 30 30 30 30 30 30 30 30 35 35 35 35 35 35\n",
      " 35 35 35 35 35 35 35 35 40 40 40 40 40 40 40 40 40 40 40 40 40 40 50 50 50\n",
      " 50 50 50 50 50 50 50 50 50 50 50],\n",
      "             mask = [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'param_n_neighbors': masked_array(data = [5 5 8 8 10 10 12 12 15 15 20 20 25 25 5 5 8 8 10 10 12 12 15 15 20 20 25\n",
      " 25 5 5 8 8 10 10 12 12 15 15 20 20 25 25 5 5 8 8 10 10 12 12 15 15 20 20\n",
      " 25 25 5 5 8 8 10 10 12 12 15 15 20 20 25 25 5 5 8 8 10 10 12 12 15 15 20\n",
      " 20 25 25 5 5 8 8 10 10 12 12 15 15 20 20 25 25 5 5 8 8 10 10 12 12 15 15\n",
      " 20 20 25 25 5 5 8 8 10 10 12 12 15 15 20 20 25 25 5 5 8 8 10 10 12 12 15\n",
      " 15 20 20 25 25 5 5 8 8 10 10 12 12 15 15 20 20 25 25 5 5 8 8 10 10 12 12\n",
      " 15 15 20 20 25 25 5 5 8 8 10 10 12 12 15 15 20 20 25 25 5 5 8 8 10 10 12\n",
      " 12 15 15 20 20 25 25 5 5 8 8 10 10 12 12 15 15 20 20 25 25 5 5 8 8 10 10\n",
      " 12 12 15 15 20 20 25 25 5 5 8 8 10 10 12 12 15 15 20 20 25 25 5 5 8 8 10\n",
      " 10 12 12 15 15 20 20 25 25 5 5 8 8 10 10 12 12 15 15 20 20 25 25 5 5 8 8\n",
      " 10 10 12 12 15 15 20 20 25 25 5 5 8 8 10 10 12 12 15 15 20 20 25 25 5 5 8\n",
      " 8 10 10 12 12 15 15 20 20 25 25 5 5 8 8 10 10 12 12 15 15 20 20 25 25 5 5\n",
      " 8 8 10 10 12 12 15 15 20 20 25 25],\n",
      "             mask = [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'param_weights': masked_array(data = ['uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'\n",
      " 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform'\n",
      " 'distance' 'uniform' 'distance' 'uniform' 'distance' 'uniform' 'distance'],\n",
      "             mask = [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'algorithm': 'ball_tree', 'leaf_size': 10, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 10, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 10, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 10, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 10, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 10, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 10, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 10, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 10, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 10, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 10, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 10, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 10, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 10, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 25, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 25, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 25, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 25, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 25, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 25, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 25, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 25, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 25, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 25, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 25, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 25, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 25, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 25, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 30, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 35, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 35, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 35, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 35, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 35, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 35, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 35, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 35, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 35, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 35, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 35, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 35, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 35, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 35, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 40, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 10, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 10, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 10, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 10, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 10, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 10, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 10, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 10, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 10, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 10, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 10, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 10, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 10, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 10, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 15, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 15, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 15, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 15, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 15, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 15, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 15, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 15, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 15, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 15, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 15, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 15, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 15, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 15, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 20, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 25, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 25, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 25, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 25, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 25, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 25, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 25, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 25, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 25, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 25, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 25, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 25, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 25, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 25, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 30, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 35, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 35, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 35, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 35, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 35, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 35, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 35, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 35, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 35, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 35, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 35, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 35, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 35, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 35, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 40, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'kd_tree', 'leaf_size': 50, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 15, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 15, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 15, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 15, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 15, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 15, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 15, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 15, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 15, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 15, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 15, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 15, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 15, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 15, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 20, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 20, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 20, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 20, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 20, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 20, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 20, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 20, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 20, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 20, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 20, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 20, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 20, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 20, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 25, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 25, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 25, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 25, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 25, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 25, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 25, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 25, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 25, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 25, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 25, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 25, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 25, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 25, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 30, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 35, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 35, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 35, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 35, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 35, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 35, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 35, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 35, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 35, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 35, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 35, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 35, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 35, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 35, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 40, 'n_neighbors': 25, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 5, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 5, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 8, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 8, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 10, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 10, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 12, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 12, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 15, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 15, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 20, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 20, 'weights': 'distance'}, {'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 25, 'weights': 'uniform'}, {'algorithm': 'brute', 'leaf_size': 50, 'n_neighbors': 25, 'weights': 'distance'}], 'split0_test_score': array([ 0.22365699,  0.2162694 ,  0.2402699 ,  0.22327296,  0.25274337,\n",
      "        0.22676822,  0.25625782,  0.22452756,  0.24744734,  0.2210413 ,\n",
      "        0.2321124 ,  0.22502418,  0.23170528,  0.23035161,  0.22548366,\n",
      "        0.21581231,  0.23516422,  0.22030783,  0.2528821 ,  0.22467984,\n",
      "        0.26120935,  0.22718784,  0.24637621,  0.22189344,  0.23278375,\n",
      "        0.22535906,  0.23717477,  0.23198496,  0.22548366,  0.21581231,\n",
      "        0.23516422,  0.22030783,  0.2528821 ,  0.22467984,  0.26120935,\n",
      "        0.22718784,  0.24637621,  0.22189344,  0.23278375,  0.22535906,\n",
      "        0.23717477,  0.23198496,  0.22548366,  0.21581231,  0.23516422,\n",
      "        0.22030783,  0.2528821 ,  0.22467984,  0.26120935,  0.22718784,\n",
      "        0.24637621,  0.22189344,  0.23278375,  0.22535906,  0.23717477,\n",
      "        0.23198496,  0.22549606,  0.21701759,  0.23641972,  0.21987295,\n",
      "        0.25229476,  0.2260032 ,  0.25670816,  0.22572664,  0.24376291,\n",
      "        0.22124051,  0.23334887,  0.22535856,  0.23635494,  0.23255899,\n",
      "        0.22549606,  0.21701759,  0.23641972,  0.21987295,  0.25229476,\n",
      "        0.2260032 ,  0.25670816,  0.22572664,  0.24376291,  0.22124051,\n",
      "        0.23334887,  0.22535856,  0.23635494,  0.23255899,  0.22549606,\n",
      "        0.21701759,  0.23641972,  0.21987295,  0.25229476,  0.2260032 ,\n",
      "        0.25670816,  0.22572664,  0.24376291,  0.22124051,  0.23334887,\n",
      "        0.22535856,  0.23635494,  0.23255899,  0.22549606,  0.21701759,\n",
      "        0.23641972,  0.21987295,  0.25229476,  0.2260032 ,  0.25670816,\n",
      "        0.22572664,  0.24376291,  0.22124051,  0.23334887,  0.22535856,\n",
      "        0.23635494,  0.23255899,  0.22259771,  0.21626408,  0.23548185,\n",
      "        0.22234119,  0.24861808,  0.2259308 ,  0.25453439,  0.22469283,\n",
      "        0.24292565,  0.22158906,  0.23359854,  0.22577132,  0.23301331,\n",
      "        0.23123085,  0.22717718,  0.21646911,  0.23264674,  0.22065433,\n",
      "        0.25464235,  0.22527066,  0.25591405,  0.22509998,  0.24891207,\n",
      "        0.22221856,  0.23221561,  0.22532642,  0.23656647,  0.23140982,\n",
      "        0.22717718,  0.21646911,  0.23264674,  0.22065433,  0.25464235,\n",
      "        0.22527066,  0.25591405,  0.22509998,  0.24891207,  0.22221856,\n",
      "        0.23221561,  0.22532642,  0.23656647,  0.23140982,  0.22717718,\n",
      "        0.21646911,  0.23264674,  0.22065433,  0.25464235,  0.22527066,\n",
      "        0.25591405,  0.22509998,  0.24891207,  0.22221856,  0.23221561,\n",
      "        0.22532642,  0.23656647,  0.23140982,  0.22463673,  0.21619826,\n",
      "        0.2338891 ,  0.220947  ,  0.25611311,  0.22643231,  0.26345833,\n",
      "        0.22721941,  0.24581347,  0.2221228 ,  0.23211238,  0.22487637,\n",
      "        0.23278608,  0.23107312,  0.22463673,  0.21619826,  0.2338891 ,\n",
      "        0.220947  ,  0.25611311,  0.22643231,  0.26345833,  0.22721941,\n",
      "        0.24581347,  0.2221228 ,  0.23211238,  0.22487637,  0.23278608,\n",
      "        0.23107312,  0.22463673,  0.21619826,  0.2338891 ,  0.220947  ,\n",
      "        0.25611311,  0.22643231,  0.26345833,  0.22721941,  0.24581347,\n",
      "        0.2221228 ,  0.23211238,  0.22487637,  0.23278608,  0.23107312,\n",
      "        0.22463673,  0.21619826,  0.2338891 ,  0.220947  ,  0.25611311,\n",
      "        0.22643231,  0.26345833,  0.22721941,  0.24581347,  0.2221228 ,\n",
      "        0.23211238,  0.22487637,  0.23278608,  0.23107312,  0.23848234,\n",
      "        0.21255831,  0.22302669,  0.21766943,  0.25390538,  0.22541818,\n",
      "        0.25543721,  0.2233391 ,  0.23946334,  0.22024207,  0.230381  ,\n",
      "        0.22535099,  0.23793319,  0.23227862,  0.23848234,  0.21255831,\n",
      "        0.22302669,  0.21766943,  0.25390538,  0.22541818,  0.25543721,\n",
      "        0.2233391 ,  0.23946334,  0.22024207,  0.230381  ,  0.22535099,\n",
      "        0.23793319,  0.23227862,  0.23848234,  0.21255831,  0.22302669,\n",
      "        0.21766943,  0.25390538,  0.22541818,  0.25543721,  0.2233391 ,\n",
      "        0.23946334,  0.22024207,  0.230381  ,  0.22535099,  0.23793319,\n",
      "        0.23227862,  0.23848234,  0.21255831,  0.22302669,  0.21766943,\n",
      "        0.25390538,  0.22541818,  0.25543721,  0.2233391 ,  0.23946334,\n",
      "        0.22024207,  0.230381  ,  0.22535099,  0.23793319,  0.23227862,\n",
      "        0.23848234,  0.21255831,  0.22302669,  0.21766943,  0.25390538,\n",
      "        0.22541818,  0.25543721,  0.2233391 ,  0.23946334,  0.22024207,\n",
      "        0.230381  ,  0.22535099,  0.23793319,  0.23227862,  0.23848234,\n",
      "        0.21255831,  0.22302669,  0.21766943,  0.25390538,  0.22541818,\n",
      "        0.25543721,  0.2233391 ,  0.23946334,  0.22024207,  0.230381  ,\n",
      "        0.22535099,  0.23793319,  0.23227862,  0.23848234,  0.21255831,\n",
      "        0.22302669,  0.21766943,  0.25390538,  0.22541818,  0.25543721,\n",
      "        0.2233391 ,  0.23946334,  0.22024207,  0.230381  ,  0.22535099,\n",
      "        0.23793319,  0.23227862,  0.23848234,  0.21255831,  0.22302669,\n",
      "        0.21766943,  0.25390538,  0.22541818,  0.25543721,  0.2233391 ,\n",
      "        0.23946334,  0.22024207,  0.230381  ,  0.22535099,  0.23793319,\n",
      "        0.23227862]), 'split1_test_score': array([ 0.16656917,  0.10649137,  0.18196039,  0.11526984,  0.20193732,\n",
      "        0.12339731,  0.21188329,  0.12790592,  0.19409015,  0.12863986,\n",
      "        0.17579536,  0.13369387,  0.18153184,  0.14006212,  0.15966257,\n",
      "        0.10836525,  0.18810946,  0.11651278,  0.20362085,  0.12552826,\n",
      "        0.21677061,  0.12876773,  0.19896012,  0.12722213,  0.17628196,\n",
      "        0.13502395,  0.18257092,  0.14027836,  0.15966257,  0.10836525,\n",
      "        0.18810946,  0.11651278,  0.20362085,  0.12552826,  0.21677061,\n",
      "        0.12876773,  0.19896012,  0.12722213,  0.17628196,  0.13502395,\n",
      "        0.18257092,  0.14027836,  0.15966257,  0.10836525,  0.18810946,\n",
      "        0.11651278,  0.20362085,  0.12552826,  0.21677061,  0.12876773,\n",
      "        0.19896012,  0.12722213,  0.17628196,  0.13502395,  0.18257092,\n",
      "        0.14027836,  0.14293724,  0.09448727,  0.18796891,  0.12030625,\n",
      "        0.20697898,  0.12797722,  0.21786498,  0.13175072,  0.19234376,\n",
      "        0.12718101,  0.17766639,  0.13521685,  0.18039222,  0.14012501,\n",
      "        0.14293724,  0.09448727,  0.18796891,  0.12030625,  0.20697898,\n",
      "        0.12797722,  0.21786498,  0.13175072,  0.19234376,  0.12718101,\n",
      "        0.17766639,  0.13521685,  0.18039222,  0.14012501,  0.14293724,\n",
      "        0.09448727,  0.18796891,  0.12030625,  0.20697898,  0.12797722,\n",
      "        0.21786498,  0.13175072,  0.19234376,  0.12718101,  0.17766639,\n",
      "        0.13521685,  0.18039222,  0.14012501,  0.14293724,  0.09448727,\n",
      "        0.18796891,  0.12030625,  0.20697898,  0.12797722,  0.21786498,\n",
      "        0.13175072,  0.19234376,  0.12718101,  0.17766639,  0.13521685,\n",
      "        0.18039222,  0.14012501,  0.16464652,  0.10629312,  0.17699053,\n",
      "        0.11474722,  0.19856867,  0.12365993,  0.211352  ,  0.1285252 ,\n",
      "        0.19344679,  0.12864282,  0.17868945,  0.13507987,  0.18882719,\n",
      "        0.14209714,  0.15442171,  0.10673552,  0.18452696,  0.11466415,\n",
      "        0.2009819 ,  0.12587292,  0.21331364,  0.12911737,  0.19621977,\n",
      "        0.12856478,  0.17605027,  0.13482709,  0.18674661,  0.14079763,\n",
      "        0.15442171,  0.10673552,  0.18452696,  0.11466415,  0.2009819 ,\n",
      "        0.12587292,  0.21331364,  0.12911737,  0.19621977,  0.12856478,\n",
      "        0.17605027,  0.13482709,  0.18674661,  0.14079763,  0.15442171,\n",
      "        0.10673552,  0.18452696,  0.11466415,  0.2009819 ,  0.12587292,\n",
      "        0.21331364,  0.12911737,  0.19621977,  0.12856478,  0.17605027,\n",
      "        0.13482709,  0.18674661,  0.14079763,  0.14374524,  0.09519697,\n",
      "        0.18803355,  0.11854681,  0.20704379,  0.12818899,  0.21966722,\n",
      "        0.13207939,  0.1938089 ,  0.12869428,  0.1783594 ,  0.13477444,\n",
      "        0.18482781,  0.1406453 ,  0.14374524,  0.09519697,  0.18803355,\n",
      "        0.11854681,  0.20704379,  0.12818899,  0.21966722,  0.13207939,\n",
      "        0.1938089 ,  0.12869428,  0.1783594 ,  0.13477444,  0.18482781,\n",
      "        0.1406453 ,  0.14374524,  0.09519697,  0.18803355,  0.11854681,\n",
      "        0.20704379,  0.12818899,  0.21966722,  0.13207939,  0.1938089 ,\n",
      "        0.12869428,  0.1783594 ,  0.13477444,  0.18482781,  0.1406453 ,\n",
      "        0.14374524,  0.09519697,  0.18803355,  0.11854681,  0.20704379,\n",
      "        0.12818899,  0.21966722,  0.13207939,  0.1938089 ,  0.12869428,\n",
      "        0.1783594 ,  0.13477444,  0.18482781,  0.1406453 ,  0.15563932,\n",
      "        0.109466  ,  0.19438311,  0.12659028,  0.2265137 ,  0.13777424,\n",
      "        0.22785272,  0.13931449,  0.20845905,  0.1353448 ,  0.17975651,\n",
      "        0.13437322,  0.18550782,  0.13995588,  0.15563932,  0.109466  ,\n",
      "        0.19438311,  0.12659028,  0.2265137 ,  0.13777424,  0.22785272,\n",
      "        0.13931449,  0.20845905,  0.1353448 ,  0.17975651,  0.13437322,\n",
      "        0.18550782,  0.13995588,  0.15563932,  0.109466  ,  0.19438311,\n",
      "        0.12659028,  0.2265137 ,  0.13777424,  0.22785272,  0.13931449,\n",
      "        0.20845905,  0.1353448 ,  0.17975651,  0.13437322,  0.18550782,\n",
      "        0.13995588,  0.15563932,  0.109466  ,  0.19438311,  0.12659028,\n",
      "        0.2265137 ,  0.13777424,  0.22785272,  0.13931449,  0.20845905,\n",
      "        0.1353448 ,  0.17975651,  0.13437322,  0.18550782,  0.13995588,\n",
      "        0.15563932,  0.109466  ,  0.19438311,  0.12659028,  0.2265137 ,\n",
      "        0.13777424,  0.22785272,  0.13931449,  0.20845905,  0.1353448 ,\n",
      "        0.17975651,  0.13437322,  0.18550782,  0.13995588,  0.15563932,\n",
      "        0.109466  ,  0.19438311,  0.12659028,  0.2265137 ,  0.13777424,\n",
      "        0.22785272,  0.13931449,  0.20845905,  0.1353448 ,  0.17975651,\n",
      "        0.13437322,  0.18550782,  0.13995588,  0.15563932,  0.109466  ,\n",
      "        0.19438311,  0.12659028,  0.2265137 ,  0.13777424,  0.22785272,\n",
      "        0.13931449,  0.20845905,  0.1353448 ,  0.17975651,  0.13437322,\n",
      "        0.18550782,  0.13995588,  0.15563932,  0.109466  ,  0.19438311,\n",
      "        0.12659028,  0.2265137 ,  0.13777424,  0.22785272,  0.13931449,\n",
      "        0.20845905,  0.1353448 ,  0.17975651,  0.13437322,  0.18550782,\n",
      "        0.13995588]), 'split2_test_score': array([ 0.17714354,  0.10226225,  0.20253539,  0.11182681,  0.18483923,\n",
      "        0.10884631,  0.17966719,  0.10839242,  0.18093314,  0.10794185,\n",
      "        0.20447683,  0.11736113,  0.19226492,  0.11883088,  0.18683671,\n",
      "        0.10584109,  0.20447252,  0.11553179,  0.18510889,  0.10694646,\n",
      "        0.18213159,  0.10824291,  0.18134991,  0.10782383,  0.20371737,\n",
      "        0.11580692,  0.19200495,  0.11807804,  0.18683671,  0.10584109,\n",
      "        0.20447252,  0.11553179,  0.18510889,  0.10694646,  0.18213159,\n",
      "        0.10824291,  0.18134991,  0.10782383,  0.20371737,  0.11580692,\n",
      "        0.19200495,  0.11807804,  0.18683671,  0.10584109,  0.20447252,\n",
      "        0.11553179,  0.18510889,  0.10694646,  0.18213159,  0.10824291,\n",
      "        0.18134991,  0.10782383,  0.20371737,  0.11580692,  0.19200495,\n",
      "        0.11807804,  0.17855687,  0.10271142,  0.20393665,  0.1143883 ,\n",
      "        0.19312411,  0.11106396,  0.18466937,  0.10979597,  0.18714143,\n",
      "        0.10869822,  0.2009072 ,  0.11524954,  0.19137894,  0.11790689,\n",
      "        0.17855687,  0.10271142,  0.20393665,  0.1143883 ,  0.19312411,\n",
      "        0.11106396,  0.18466937,  0.10979597,  0.18714143,  0.10869822,\n",
      "        0.2009072 ,  0.11524954,  0.19137894,  0.11790689,  0.17855687,\n",
      "        0.10271142,  0.20393665,  0.1143883 ,  0.19312411,  0.11106396,\n",
      "        0.18466937,  0.10979597,  0.18714143,  0.10869822,  0.2009072 ,\n",
      "        0.11524954,  0.19137894,  0.11790689,  0.17855687,  0.10271142,\n",
      "        0.20393665,  0.1143883 ,  0.19312411,  0.11106396,  0.18466937,\n",
      "        0.10979597,  0.18714143,  0.10869822,  0.2009072 ,  0.11524954,\n",
      "        0.19137894,  0.11790689,  0.17835327,  0.10455967,  0.19455181,\n",
      "        0.11080881,  0.18767331,  0.1091595 ,  0.17850201,  0.10748901,\n",
      "        0.18422389,  0.10792774,  0.20192781,  0.11582211,  0.19113806,\n",
      "        0.11824669,  0.18466031,  0.10377462,  0.20017869,  0.11390311,\n",
      "        0.18406919,  0.10771125,  0.18272572,  0.10831814,  0.18430303,\n",
      "        0.10744018,  0.20179563,  0.11542204,  0.19013777,  0.11788863,\n",
      "        0.18466031,  0.10377462,  0.20017869,  0.11390311,  0.18406919,\n",
      "        0.10771125,  0.18272572,  0.10831814,  0.18430303,  0.10744018,\n",
      "        0.20179563,  0.11542204,  0.19013777,  0.11788863,  0.18466031,\n",
      "        0.10377462,  0.20017869,  0.11390311,  0.18406919,  0.10771125,\n",
      "        0.18272572,  0.10831814,  0.18430303,  0.10744018,  0.20179563,\n",
      "        0.11542204,  0.19013777,  0.11788863,  0.18361408,  0.10531038,\n",
      "        0.2016174 ,  0.11259313,  0.18837544,  0.1096529 ,  0.18389931,\n",
      "        0.11037291,  0.18108171,  0.10692899,  0.202243  ,  0.11592757,\n",
      "        0.19241252,  0.1187803 ,  0.18361408,  0.10531038,  0.2016174 ,\n",
      "        0.11259313,  0.18837544,  0.1096529 ,  0.18389931,  0.11037291,\n",
      "        0.18108171,  0.10692899,  0.202243  ,  0.11592757,  0.19241252,\n",
      "        0.1187803 ,  0.18361408,  0.10531038,  0.2016174 ,  0.11259313,\n",
      "        0.18837544,  0.1096529 ,  0.18389931,  0.11037291,  0.18108171,\n",
      "        0.10692899,  0.202243  ,  0.11592757,  0.19241252,  0.1187803 ,\n",
      "        0.18361408,  0.10531038,  0.2016174 ,  0.11259313,  0.18837544,\n",
      "        0.1096529 ,  0.18389931,  0.11037291,  0.18108171,  0.10692899,\n",
      "        0.202243  ,  0.11592757,  0.19241252,  0.1187803 ,  0.17713559,\n",
      "        0.09818276,  0.20562881,  0.11522681,  0.19448864,  0.11458809,\n",
      "        0.18220349,  0.10778685,  0.17900246,  0.10407782,  0.20335089,\n",
      "        0.11459363,  0.1925439 ,  0.11914434,  0.17713559,  0.09818276,\n",
      "        0.20562881,  0.11522681,  0.19448864,  0.11458809,  0.18220349,\n",
      "        0.10778685,  0.17900246,  0.10407782,  0.20335089,  0.11459363,\n",
      "        0.1925439 ,  0.11914434,  0.17713559,  0.09818276,  0.20562881,\n",
      "        0.11522681,  0.19448864,  0.11458809,  0.18220349,  0.10778685,\n",
      "        0.17900246,  0.10407782,  0.20335089,  0.11459363,  0.1925439 ,\n",
      "        0.11914434,  0.17713559,  0.09818276,  0.20562881,  0.11522681,\n",
      "        0.19448864,  0.11458809,  0.18220349,  0.10778685,  0.17900246,\n",
      "        0.10407782,  0.20335089,  0.11459363,  0.1925439 ,  0.11914434,\n",
      "        0.17713559,  0.09818276,  0.20562881,  0.11522681,  0.19448864,\n",
      "        0.11458809,  0.18220349,  0.10778685,  0.17900246,  0.10407782,\n",
      "        0.20335089,  0.11459363,  0.1925439 ,  0.11914434,  0.17713559,\n",
      "        0.09818276,  0.20562881,  0.11522681,  0.19448864,  0.11458809,\n",
      "        0.18220349,  0.10778685,  0.17900246,  0.10407782,  0.20335089,\n",
      "        0.11459363,  0.1925439 ,  0.11914434,  0.17713559,  0.09818276,\n",
      "        0.20562881,  0.11522681,  0.19448864,  0.11458809,  0.18220349,\n",
      "        0.10778685,  0.17900246,  0.10407782,  0.20335089,  0.11459363,\n",
      "        0.1925439 ,  0.11914434,  0.17713559,  0.09818276,  0.20562881,\n",
      "        0.11522681,  0.19448864,  0.11458809,  0.18220349,  0.10778685,\n",
      "        0.17900246,  0.10407782,  0.20335089,  0.11459363,  0.1925439 ,\n",
      "        0.11914434]), 'mean_test_score': array([ 0.18912323,  0.14167434,  0.20825522,  0.1501232 ,  0.21317331,\n",
      "        0.15300395,  0.2159361 ,  0.15360863,  0.20749021,  0.152541  ,\n",
      "        0.2041282 ,  0.15869306,  0.20183401,  0.16308154,  0.19066098,\n",
      "        0.14333955,  0.20924873,  0.15078413,  0.21387061,  0.15238486,\n",
      "        0.22003718,  0.15473283,  0.20889541,  0.15231313,  0.20426103,\n",
      "        0.15872998,  0.20391688,  0.16344712,  0.19066098,  0.14333955,\n",
      "        0.20924873,  0.15078413,  0.21387061,  0.15238486,  0.22003718,\n",
      "        0.15473283,  0.20889541,  0.15231313,  0.20426103,  0.15872998,\n",
      "        0.20391688,  0.16344712,  0.19066098,  0.14333955,  0.20924873,\n",
      "        0.15078413,  0.21387061,  0.15238486,  0.22003718,  0.15473283,\n",
      "        0.20889541,  0.15231313,  0.20426103,  0.15872998,  0.20391688,\n",
      "        0.16344712,  0.18233006,  0.13807209,  0.20944176,  0.1515225 ,\n",
      "        0.21746595,  0.15501479,  0.2197475 ,  0.15575778,  0.20774937,\n",
      "        0.15237325,  0.20397415,  0.15860832,  0.2027087 ,  0.1635303 ,\n",
      "        0.18233006,  0.13807209,  0.20944176,  0.1515225 ,  0.21746595,\n",
      "        0.15501479,  0.2197475 ,  0.15575778,  0.20774937,  0.15237325,\n",
      "        0.20397415,  0.15860832,  0.2027087 ,  0.1635303 ,  0.18233006,\n",
      "        0.13807209,  0.20944176,  0.1515225 ,  0.21746595,  0.15501479,\n",
      "        0.2197475 ,  0.15575778,  0.20774937,  0.15237325,  0.20397415,\n",
      "        0.15860832,  0.2027087 ,  0.1635303 ,  0.18233006,  0.13807209,\n",
      "        0.20944176,  0.1515225 ,  0.21746595,  0.15501479,  0.2197475 ,\n",
      "        0.15575778,  0.20774937,  0.15237325,  0.20397415,  0.15860832,\n",
      "        0.2027087 ,  0.1635303 ,  0.1885325 ,  0.14237229,  0.2023414 ,\n",
      "        0.14929908,  0.21162002,  0.15291674,  0.21479613,  0.15356901,\n",
      "        0.20686544,  0.15271987,  0.2047386 ,  0.1588911 ,  0.20432619,\n",
      "        0.16385823,  0.18875307,  0.14232642,  0.20578413,  0.14974053,\n",
      "        0.21323115,  0.15295161,  0.2173178 ,  0.1541785 ,  0.20981162,\n",
      "        0.15274117,  0.20335384,  0.15852518,  0.20448362,  0.16336536,\n",
      "        0.18875307,  0.14232642,  0.20578413,  0.14974053,  0.21323115,\n",
      "        0.15295161,  0.2173178 ,  0.1541785 ,  0.20981162,  0.15274117,\n",
      "        0.20335384,  0.15852518,  0.20448362,  0.16336536,  0.18875307,\n",
      "        0.14232642,  0.20578413,  0.14974053,  0.21323115,  0.15295161,\n",
      "        0.2173178 ,  0.1541785 ,  0.20981162,  0.15274117,  0.20335384,\n",
      "        0.15852518,  0.20448362,  0.16336536,  0.18399868,  0.13890187,\n",
      "        0.20784668,  0.15069565,  0.21717745,  0.15475807,  0.22234162,\n",
      "        0.15655723,  0.20690136,  0.15258202,  0.20423826,  0.15852613,\n",
      "        0.20334213,  0.16349957,  0.18399868,  0.13890187,  0.20784668,\n",
      "        0.15069565,  0.21717745,  0.15475807,  0.22234162,  0.15655723,\n",
      "        0.20690136,  0.15258202,  0.20423826,  0.15852613,  0.20334213,\n",
      "        0.16349957,  0.18399868,  0.13890187,  0.20784668,  0.15069565,\n",
      "        0.21717745,  0.15475807,  0.22234162,  0.15655723,  0.20690136,\n",
      "        0.15258202,  0.20423826,  0.15852613,  0.20334213,  0.16349957,\n",
      "        0.18399868,  0.13890187,  0.20784668,  0.15069565,  0.21717745,\n",
      "        0.15475807,  0.22234162,  0.15655723,  0.20690136,  0.15258202,\n",
      "        0.20423826,  0.15852613,  0.20334213,  0.16349957,  0.19041908,\n",
      "        0.14006903,  0.20767953,  0.15316218,  0.22496924,  0.15926017,\n",
      "        0.22183114,  0.15681348,  0.20897495,  0.15322156,  0.20449614,\n",
      "        0.15810595,  0.2053283 ,  0.16379294,  0.19041908,  0.14006903,\n",
      "        0.20767953,  0.15316218,  0.22496924,  0.15926017,  0.22183114,\n",
      "        0.15681348,  0.20897495,  0.15322156,  0.20449614,  0.15810595,\n",
      "        0.2053283 ,  0.16379294,  0.19041908,  0.14006903,  0.20767953,\n",
      "        0.15316218,  0.22496924,  0.15926017,  0.22183114,  0.15681348,\n",
      "        0.20897495,  0.15322156,  0.20449614,  0.15810595,  0.2053283 ,\n",
      "        0.16379294,  0.19041908,  0.14006903,  0.20767953,  0.15316218,\n",
      "        0.22496924,  0.15926017,  0.22183114,  0.15681348,  0.20897495,\n",
      "        0.15322156,  0.20449614,  0.15810595,  0.2053283 ,  0.16379294,\n",
      "        0.19041908,  0.14006903,  0.20767953,  0.15316218,  0.22496924,\n",
      "        0.15926017,  0.22183114,  0.15681348,  0.20897495,  0.15322156,\n",
      "        0.20449614,  0.15810595,  0.2053283 ,  0.16379294,  0.19041908,\n",
      "        0.14006903,  0.20767953,  0.15316218,  0.22496924,  0.15926017,\n",
      "        0.22183114,  0.15681348,  0.20897495,  0.15322156,  0.20449614,\n",
      "        0.15810595,  0.2053283 ,  0.16379294,  0.19041908,  0.14006903,\n",
      "        0.20767953,  0.15316218,  0.22496924,  0.15926017,  0.22183114,\n",
      "        0.15681348,  0.20897495,  0.15322156,  0.20449614,  0.15810595,\n",
      "        0.2053283 ,  0.16379294,  0.19041908,  0.14006903,  0.20767953,\n",
      "        0.15316218,  0.22496924,  0.15926017,  0.22183114,  0.15681348,\n",
      "        0.20897495,  0.15322156,  0.20449614,  0.15810595,  0.2053283 ,\n",
      "        0.16379294]), 'std_test_score': array([ 0.02479771,  0.05277492,  0.0241459 ,  0.05174378,  0.02883781,\n",
      "        0.05249641,  0.03139905,  0.05077608,  0.02875999,  0.04916855,\n",
      "        0.02299266,  0.04737477,  0.02157188,  0.04835038,  0.02700707,\n",
      "        0.05125634,  0.01950464,  0.04916231,  0.02860181,  0.05168007,\n",
      "        0.03236589,  0.05191412,  0.02746073,  0.04983398,  0.02306997,\n",
      "        0.04776261,  0.02383017,  0.04930376,  0.02700707,  0.05125634,\n",
      "        0.01950464,  0.04916231,  0.02860181,  0.05168007,  0.03236589,\n",
      "        0.05191412,  0.02746073,  0.04983398,  0.02306997,  0.04776261,\n",
      "        0.02383017,  0.04930376,  0.02700707,  0.05125634,  0.01950464,\n",
      "        0.04916231,  0.02860181,  0.05168007,  0.03236589,  0.05191412,\n",
      "        0.02746073,  0.04983398,  0.02306997,  0.04776261,  0.02383017,\n",
      "        0.04930376,  0.03380994,  0.05592377,  0.02015936,  0.04839142,\n",
      "        0.02526887,  0.05066906,  0.02943982,  0.05028077,  0.02555383,\n",
      "        0.04927764,  0.02283549,  0.04789829,  0.02421059,  0.04964629,\n",
      "        0.03380994,  0.05592377,  0.02015936,  0.04839142,  0.02526887,\n",
      "        0.05066906,  0.02943982,  0.05028077,  0.02555383,  0.04927764,\n",
      "        0.02283549,  0.04789829,  0.02421059,  0.04964629,  0.03380994,\n",
      "        0.05592377,  0.02015936,  0.04839142,  0.02526887,  0.05066906,\n",
      "        0.02943982,  0.05028077,  0.02555383,  0.04927764,  0.02283549,\n",
      "        0.04789829,  0.02421059,  0.04964629,  0.03380994,  0.05592377,\n",
      "        0.02015936,  0.04839142,  0.02526887,  0.05066906,  0.02943982,\n",
      "        0.05028077,  0.02555383,  0.04927764,  0.02283549,  0.04789829,\n",
      "        0.02421059,  0.04964629,  0.02472917,  0.05225418,  0.02450601,\n",
      "        0.05167359,  0.02653701,  0.05196701,  0.03113548,  0.05102012,\n",
      "        0.02577491,  0.04942673,  0.02250448,  0.04794051,  0.02030678,\n",
      "        0.04862451,  0.02984295,  0.05244074,  0.02004069,  0.05014459,\n",
      "        0.03008517,  0.05167202,  0.03001286,  0.05086285,  0.02807295,\n",
      "        0.04987914,  0.02295586,  0.04789532,  0.02272821,  0.04901525,\n",
      "        0.02984295,  0.05244074,  0.02004069,  0.05014459,  0.03008517,\n",
      "        0.05167202,  0.03001286,  0.05086285,  0.02807295,  0.04987914,\n",
      "        0.02295586,  0.04789532,  0.02272821,  0.04901525,  0.02984295,\n",
      "        0.05244074,  0.02004069,  0.05014459,  0.03008517,  0.05167202,\n",
      "        0.03001286,  0.05086285,  0.02807295,  0.04987914,  0.02295586,\n",
      "        0.04789532,  0.02272821,  0.04901525,  0.03302493,  0.05481253,\n",
      "        0.01923167,  0.04973464,  0.02856707,  0.05124318,  0.03253484,\n",
      "        0.05074544,  0.0280013 ,  0.04996914,  0.02198987,  0.04754344,\n",
      "        0.02104901,  0.04860835,  0.03302493,  0.05481253,  0.01923167,\n",
      "        0.04973464,  0.02856707,  0.05124318,  0.03253484,  0.05074544,\n",
      "        0.0280013 ,  0.04996914,  0.02198987,  0.04754344,  0.02104901,\n",
      "        0.04860835,  0.03302493,  0.05481253,  0.01923167,  0.04973464,\n",
      "        0.02856707,  0.05124318,  0.03253484,  0.05074544,  0.0280013 ,\n",
      "        0.04996914,  0.02198987,  0.04754344,  0.02104901,  0.04860835,\n",
      "        0.03302493,  0.05481253,  0.01923167,  0.04973464,  0.02856707,\n",
      "        0.05124318,  0.03253484,  0.05074544,  0.0280013 ,  0.04996914,\n",
      "        0.02198987,  0.04754344,  0.02104901,  0.04860835,  0.03510062,\n",
      "        0.05146423,  0.01178326,  0.04584882,  0.02428135,  0.04772883,\n",
      "        0.03019922,  0.04876981,  0.02468575,  0.04907965,  0.02068322,\n",
      "        0.04823021,  0.02323339,  0.04916635,  0.03510062,  0.05146423,\n",
      "        0.01178326,  0.04584882,  0.02428135,  0.04772883,  0.03019922,\n",
      "        0.04876981,  0.02468575,  0.04907965,  0.02068322,  0.04823021,\n",
      "        0.02323339,  0.04916635,  0.03510062,  0.05146423,  0.01178326,\n",
      "        0.04584882,  0.02428135,  0.04772883,  0.03019922,  0.04876981,\n",
      "        0.02468575,  0.04907965,  0.02068322,  0.04823021,  0.02323339,\n",
      "        0.04916635,  0.03510062,  0.05146423,  0.01178326,  0.04584882,\n",
      "        0.02428135,  0.04772883,  0.03019922,  0.04876981,  0.02468575,\n",
      "        0.04907965,  0.02068322,  0.04823021,  0.02323339,  0.04916635,\n",
      "        0.03510062,  0.05146423,  0.01178326,  0.04584882,  0.02428135,\n",
      "        0.04772883,  0.03019922,  0.04876981,  0.02468575,  0.04907965,\n",
      "        0.02068322,  0.04823021,  0.02323339,  0.04916635,  0.03510062,\n",
      "        0.05146423,  0.01178326,  0.04584882,  0.02428135,  0.04772883,\n",
      "        0.03019922,  0.04876981,  0.02468575,  0.04907965,  0.02068322,\n",
      "        0.04823021,  0.02323339,  0.04916635,  0.03510062,  0.05146423,\n",
      "        0.01178326,  0.04584882,  0.02428135,  0.04772883,  0.03019922,\n",
      "        0.04876981,  0.02468575,  0.04907965,  0.02068322,  0.04823021,\n",
      "        0.02323339,  0.04916635,  0.03510062,  0.05146423,  0.01178326,\n",
      "        0.04584882,  0.02428135,  0.04772883,  0.03019922,  0.04876981,\n",
      "        0.02468575,  0.04907965,  0.02068322,  0.04823021,  0.02323339,\n",
      "        0.04916635]), 'rank_test_score': array([156, 320,  70, 308,  47, 273,  39, 255,  87, 286, 124, 205, 144,\n",
      "       192, 145, 313,  56, 301,  41, 287,  21, 249,  67, 294, 117, 202,\n",
      "       129, 186, 145, 313,  56, 301,  41, 287,  21, 249,  67, 294, 117,\n",
      "       202, 129, 186, 145, 313,  56, 301,  41, 287,  21, 249,  67, 294,\n",
      "       117, 202, 129, 186, 165, 333,  52, 297,  28, 241,  24, 237,  75,\n",
      "       290, 125, 206, 139, 178, 165, 333,  52, 297,  28, 241,  24, 237,\n",
      "        75, 290, 125, 206, 139, 178, 165, 333,  52, 297,  28, 241,  24,\n",
      "       237,  75, 290, 125, 206, 139, 178, 165, 333,  52, 297,  28, 241,\n",
      "        24, 237,  75, 290, 125, 206, 139, 178, 160, 316, 143, 312,  48,\n",
      "       277,  40, 256,  92, 281, 104, 201, 116, 169, 157, 317,  93, 309,\n",
      "        44, 274,  32, 252,  49, 278, 132, 214, 113, 189, 157, 317,  93,\n",
      "       309,  44, 274,  32, 252,  49, 278, 132, 214, 113, 189, 157, 317,\n",
      "        93, 309,  44, 274,  32, 252,  49, 278, 132, 214, 113, 189, 161,\n",
      "       329,  71, 304,  35, 245,   9, 233,  88, 282, 120, 210, 135, 182,\n",
      "       161, 329,  71, 304,  35, 245,   9, 233,  88, 282, 120, 210, 135,\n",
      "       182, 161, 329,  71, 304,  35, 245,   9, 233,  88, 282, 120, 210,\n",
      "       135, 182, 161, 329,  71, 304,  35, 245,   9, 233,  88, 282, 120,\n",
      "       210, 135, 182, 148, 321,  79, 265,   1, 193,  13, 225,  59, 257,\n",
      "       105, 217,  96, 170, 148, 321,  79, 265,   1, 193,  13, 225,  59,\n",
      "       257, 105, 217,  96, 170, 148, 321,  79, 265,   1, 193,  13, 225,\n",
      "        59, 257, 105, 217,  96, 170, 148, 321,  79, 265,   1, 193,  13,\n",
      "       225,  59, 257, 105, 217,  96, 170, 148, 321,  79, 265,   1, 193,\n",
      "        13, 225,  59, 257, 105, 217,  96, 170, 148, 321,  79, 265,   1,\n",
      "       193,  13, 225,  59, 257, 105, 217,  96, 170, 148, 321,  79, 265,\n",
      "         1, 193,  13, 225,  59, 257, 105, 217,  96, 170, 148, 321,  79,\n",
      "       265,   1, 193,  13, 225,  59, 257, 105, 217,  96, 170], dtype=int32), 'split0_train_score': array([ 0.4524656 ,  0.80826861,  0.36750382,  0.81328573,  0.32352664,\n",
      "        0.81505926,  0.30053326,  0.81501876,  0.27904369,  0.81558129,\n",
      "        0.24366154,  0.8156417 ,  0.22445594,  0.8156417 ,  0.45380526,\n",
      "        0.80826861,  0.36300061,  0.81075549,  0.32667306,  0.81505926,\n",
      "        0.2996553 ,  0.81501876,  0.27895273,  0.81562345,  0.24097639,\n",
      "        0.8156417 ,  0.22507286,  0.8156417 ,  0.45380526,  0.80826861,\n",
      "        0.36300061,  0.81075549,  0.32667306,  0.81505926,  0.2996553 ,\n",
      "        0.81501876,  0.27895273,  0.81562345,  0.24097639,  0.8156417 ,\n",
      "        0.22507286,  0.8156417 ,  0.45380526,  0.80826861,  0.36300061,\n",
      "        0.81075549,  0.32667306,  0.81505926,  0.2996553 ,  0.81501876,\n",
      "        0.27895273,  0.81562345,  0.24097639,  0.8156417 ,  0.22507286,\n",
      "        0.8156417 ,  0.45292283,  0.8089808 ,  0.36026142,  0.81075549,\n",
      "        0.32371035,  0.81505926,  0.29914728,  0.81501876,  0.28160611,\n",
      "        0.81562345,  0.24298459,  0.8156417 ,  0.22213227,  0.8156417 ,\n",
      "        0.45292283,  0.8089808 ,  0.36026142,  0.81075549,  0.32371035,\n",
      "        0.81505926,  0.29914728,  0.81501876,  0.28160611,  0.81562345,\n",
      "        0.24298459,  0.8156417 ,  0.22213227,  0.8156417 ,  0.45292283,\n",
      "        0.8089808 ,  0.36026142,  0.81075549,  0.32371035,  0.81505926,\n",
      "        0.29914728,  0.81501876,  0.28160611,  0.81562345,  0.24298459,\n",
      "        0.8156417 ,  0.22213227,  0.8156417 ,  0.45292283,  0.8089808 ,\n",
      "        0.36026142,  0.81075549,  0.32371035,  0.81505926,  0.29914728,\n",
      "        0.81501876,  0.28160611,  0.81562345,  0.24298459,  0.8156417 ,\n",
      "        0.22213227,  0.8156417 ,  0.4496865 ,  0.80826861,  0.36702736,\n",
      "        0.81328573,  0.32760542,  0.81505926,  0.29728945,  0.81501876,\n",
      "        0.27874738,  0.81558129,  0.24359977,  0.8156417 ,  0.22042892,\n",
      "        0.8156417 ,  0.4533719 ,  0.80826861,  0.3645453 ,  0.81075549,\n",
      "        0.32296533,  0.81505926,  0.30211524,  0.81501876,  0.27971187,\n",
      "        0.81562345,  0.24182983,  0.8156417 ,  0.22308047,  0.8156417 ,\n",
      "        0.4533719 ,  0.80826861,  0.3645453 ,  0.81075549,  0.32296533,\n",
      "        0.81505926,  0.30211524,  0.81501876,  0.27971187,  0.81562345,\n",
      "        0.24182983,  0.8156417 ,  0.22308047,  0.8156417 ,  0.4533719 ,\n",
      "        0.80826861,  0.3645453 ,  0.81075549,  0.32296533,  0.81505926,\n",
      "        0.30211524,  0.81501876,  0.27971187,  0.81562345,  0.24182983,\n",
      "        0.8156417 ,  0.22308047,  0.8156417 ,  0.45266052,  0.8089808 ,\n",
      "        0.36274669,  0.81075549,  0.32511103,  0.81505926,  0.30293332,\n",
      "        0.81501876,  0.28023775,  0.81562345,  0.2409819 ,  0.8156417 ,\n",
      "        0.22310311,  0.8156417 ,  0.45266052,  0.8089808 ,  0.36274669,\n",
      "        0.81075549,  0.32511103,  0.81505926,  0.30293332,  0.81501876,\n",
      "        0.28023775,  0.81562345,  0.2409819 ,  0.8156417 ,  0.22310311,\n",
      "        0.8156417 ,  0.45266052,  0.8089808 ,  0.36274669,  0.81075549,\n",
      "        0.32511103,  0.81505926,  0.30293332,  0.81501876,  0.28023775,\n",
      "        0.81562345,  0.2409819 ,  0.8156417 ,  0.22310311,  0.8156417 ,\n",
      "        0.45266052,  0.8089808 ,  0.36274669,  0.81075549,  0.32511103,\n",
      "        0.81505926,  0.30293332,  0.81501876,  0.28023775,  0.81562345,\n",
      "        0.2409819 ,  0.8156417 ,  0.22310311,  0.8156417 ,  0.45065757,\n",
      "        0.80582528,  0.36904794,  0.81465413,  0.32841846,  0.81540059,\n",
      "        0.30314479,  0.81455817,  0.27903005,  0.8155336 ,  0.24283188,\n",
      "        0.8156417 ,  0.22198252,  0.8156417 ,  0.45065757,  0.80582528,\n",
      "        0.36904794,  0.81465413,  0.32841846,  0.81540059,  0.30314479,\n",
      "        0.81455817,  0.27903005,  0.8155336 ,  0.24283188,  0.8156417 ,\n",
      "        0.22198252,  0.8156417 ,  0.45065757,  0.80582528,  0.36904794,\n",
      "        0.81465413,  0.32841846,  0.81540059,  0.30314479,  0.81455817,\n",
      "        0.27903005,  0.8155336 ,  0.24283188,  0.8156417 ,  0.22198252,\n",
      "        0.8156417 ,  0.45065757,  0.80582528,  0.36904794,  0.81465413,\n",
      "        0.32841846,  0.81540059,  0.30314479,  0.81455817,  0.27903005,\n",
      "        0.8155336 ,  0.24283188,  0.8156417 ,  0.22198252,  0.8156417 ,\n",
      "        0.45065757,  0.80582528,  0.36904794,  0.81465413,  0.32841846,\n",
      "        0.81540059,  0.30314479,  0.81455817,  0.27903005,  0.8155336 ,\n",
      "        0.24283188,  0.8156417 ,  0.22198252,  0.8156417 ,  0.45065757,\n",
      "        0.80582528,  0.36904794,  0.81465413,  0.32841846,  0.81540059,\n",
      "        0.30314479,  0.81455817,  0.27903005,  0.8155336 ,  0.24283188,\n",
      "        0.8156417 ,  0.22198252,  0.8156417 ,  0.45065757,  0.80582528,\n",
      "        0.36904794,  0.81465413,  0.32841846,  0.81540059,  0.30314479,\n",
      "        0.81455817,  0.27903005,  0.8155336 ,  0.24283188,  0.8156417 ,\n",
      "        0.22198252,  0.8156417 ,  0.45065757,  0.80582528,  0.36904794,\n",
      "        0.81465413,  0.32841846,  0.81540059,  0.30314479,  0.81455817,\n",
      "        0.27903005,  0.8155336 ,  0.24283188,  0.8156417 ,  0.22198252,\n",
      "        0.8156417 ]), 'split1_train_score': array([ 0.45843979,  0.81976884,  0.35186502,  0.81763621,  0.3314553 ,\n",
      "        0.81902798,  0.31023335,  0.81849164,  0.29613919,  0.82156885,\n",
      "        0.27736774,  0.82264583,  0.26401078,  0.82264583,  0.44199717,\n",
      "        0.813599  ,  0.35232117,  0.81917747,  0.33289392,  0.81904996,\n",
      "        0.30898214,  0.81849164,  0.29198846,  0.82156885,  0.27879506,\n",
      "        0.82264583,  0.26451123,  0.82264583,  0.44199717,  0.813599  ,\n",
      "        0.35232117,  0.81917747,  0.33289392,  0.81904996,  0.30898214,\n",
      "        0.81849164,  0.29198846,  0.82156885,  0.27879506,  0.82264583,\n",
      "        0.26451123,  0.82264583,  0.44199717,  0.813599  ,  0.35232117,\n",
      "        0.81917747,  0.33289392,  0.81904996,  0.30898214,  0.81849164,\n",
      "        0.29198846,  0.82156885,  0.27879506,  0.82264583,  0.26451123,\n",
      "        0.82264583,  0.44487888,  0.813599  ,  0.3597571 ,  0.81906985,\n",
      "        0.33220078,  0.81832602,  0.30888979,  0.81835351,  0.29299053,\n",
      "        0.82156885,  0.27904211,  0.82264583,  0.26345807,  0.82264583,\n",
      "        0.44487888,  0.813599  ,  0.3597571 ,  0.81906985,  0.33220078,\n",
      "        0.81832602,  0.30888979,  0.81835351,  0.29299053,  0.82156885,\n",
      "        0.27904211,  0.82264583,  0.26345807,  0.82264583,  0.44487888,\n",
      "        0.813599  ,  0.3597571 ,  0.81906985,  0.33220078,  0.81832602,\n",
      "        0.30888979,  0.81835351,  0.29299053,  0.82156885,  0.27904211,\n",
      "        0.82264583,  0.26345807,  0.82264583,  0.44487888,  0.813599  ,\n",
      "        0.3597571 ,  0.81906985,  0.33220078,  0.81832602,  0.30888979,\n",
      "        0.81835351,  0.29299053,  0.82156885,  0.27904211,  0.82264583,\n",
      "        0.26345807,  0.82264583,  0.44926509,  0.81976884,  0.3554137 ,\n",
      "        0.81763621,  0.33094093,  0.81902798,  0.31069448,  0.81849164,\n",
      "        0.29614745,  0.82156885,  0.27662478,  0.82264583,  0.26467216,\n",
      "        0.82264583,  0.44526754,  0.813599  ,  0.36174719,  0.81917747,\n",
      "        0.33216245,  0.81904996,  0.30624514,  0.81849164,  0.29269817,\n",
      "        0.82156885,  0.27856365,  0.82264583,  0.26386663,  0.82264583,\n",
      "        0.44526754,  0.813599  ,  0.36174719,  0.81917747,  0.33216245,\n",
      "        0.81904996,  0.30624514,  0.81849164,  0.29269817,  0.82156885,\n",
      "        0.27856365,  0.82264583,  0.26386663,  0.82264583,  0.44526754,\n",
      "        0.813599  ,  0.36174719,  0.81917747,  0.33216245,  0.81904996,\n",
      "        0.30624514,  0.81849164,  0.29269817,  0.82156885,  0.27856365,\n",
      "        0.82264583,  0.26386663,  0.82264583,  0.44520769,  0.813599  ,\n",
      "        0.36409221,  0.81906985,  0.33507613,  0.81832602,  0.30804867,\n",
      "        0.81835351,  0.29571634,  0.82156885,  0.27827098,  0.82264583,\n",
      "        0.26208633,  0.82264583,  0.44520769,  0.813599  ,  0.36409221,\n",
      "        0.81906985,  0.33507613,  0.81832602,  0.30804867,  0.81835351,\n",
      "        0.29571634,  0.82156885,  0.27827098,  0.82264583,  0.26208633,\n",
      "        0.82264583,  0.44520769,  0.813599  ,  0.36409221,  0.81906985,\n",
      "        0.33507613,  0.81832602,  0.30804867,  0.81835351,  0.29571634,\n",
      "        0.82156885,  0.27827098,  0.82264583,  0.26208633,  0.82264583,\n",
      "        0.44520769,  0.813599  ,  0.36409221,  0.81906985,  0.33507613,\n",
      "        0.81832602,  0.30804867,  0.81835351,  0.29571634,  0.82156885,\n",
      "        0.27827098,  0.82264583,  0.26208633,  0.82264583,  0.45006154,\n",
      "        0.81270688,  0.3593423 ,  0.82065707,  0.34313369,  0.82058484,\n",
      "        0.32089959,  0.8222802 ,  0.30451377,  0.8226262 ,  0.27870384,\n",
      "        0.8226262 ,  0.26403812,  0.8226262 ,  0.45006154,  0.81270688,\n",
      "        0.3593423 ,  0.82065707,  0.34313369,  0.82058484,  0.32089959,\n",
      "        0.8222802 ,  0.30451377,  0.8226262 ,  0.27870384,  0.8226262 ,\n",
      "        0.26403812,  0.8226262 ,  0.45006154,  0.81270688,  0.3593423 ,\n",
      "        0.82065707,  0.34313369,  0.82058484,  0.32089959,  0.8222802 ,\n",
      "        0.30451377,  0.8226262 ,  0.27870384,  0.8226262 ,  0.26403812,\n",
      "        0.8226262 ,  0.45006154,  0.81270688,  0.3593423 ,  0.82065707,\n",
      "        0.34313369,  0.82058484,  0.32089959,  0.8222802 ,  0.30451377,\n",
      "        0.8226262 ,  0.27870384,  0.8226262 ,  0.26403812,  0.8226262 ,\n",
      "        0.45006154,  0.81270688,  0.3593423 ,  0.82065707,  0.34313369,\n",
      "        0.82058484,  0.32089959,  0.8222802 ,  0.30451377,  0.8226262 ,\n",
      "        0.27870384,  0.8226262 ,  0.26403812,  0.8226262 ,  0.45006154,\n",
      "        0.81270688,  0.3593423 ,  0.82065707,  0.34313369,  0.82058484,\n",
      "        0.32089959,  0.8222802 ,  0.30451377,  0.8226262 ,  0.27870384,\n",
      "        0.8226262 ,  0.26403812,  0.8226262 ,  0.45006154,  0.81270688,\n",
      "        0.3593423 ,  0.82065707,  0.34313369,  0.82058484,  0.32089959,\n",
      "        0.8222802 ,  0.30451377,  0.8226262 ,  0.27870384,  0.8226262 ,\n",
      "        0.26403812,  0.8226262 ,  0.45006154,  0.81270688,  0.3593423 ,\n",
      "        0.82065707,  0.34313369,  0.82058484,  0.32089959,  0.8222802 ,\n",
      "        0.30451377,  0.8226262 ,  0.27870384,  0.8226262 ,  0.26403812,\n",
      "        0.8226262 ]), 'split2_train_score': array([ 0.474559  ,  0.82693856,  0.38658642,  0.82523915,  0.33247927,\n",
      "        0.82607319,  0.31597997,  0.82908182,  0.29384814,  0.83066821,\n",
      "        0.26675693,  0.83151614,  0.23682637,  0.83151614,  0.46889822,\n",
      "        0.82189655,  0.39194184,  0.82763454,  0.34025553,  0.82986638,\n",
      "        0.32044388,  0.83138715,  0.29211612,  0.83066821,  0.2690091 ,\n",
      "        0.83151614,  0.23683426,  0.83151614,  0.46889822,  0.82189655,\n",
      "        0.39194184,  0.82763454,  0.34025553,  0.82986638,  0.32044388,\n",
      "        0.83138715,  0.29211612,  0.83066821,  0.2690091 ,  0.83151614,\n",
      "        0.23683426,  0.83151614,  0.46889822,  0.82189655,  0.39194184,\n",
      "        0.82763454,  0.34025553,  0.82986638,  0.32044388,  0.83138715,\n",
      "        0.29211612,  0.83066821,  0.2690091 ,  0.83151614,  0.23683426,\n",
      "        0.83151614,  0.47473381,  0.82741616,  0.38715925,  0.82739681,\n",
      "        0.33295965,  0.82994944,  0.31998117,  0.83138715,  0.29459272,\n",
      "        0.83066821,  0.26656564,  0.83151614,  0.23889069,  0.83151614,\n",
      "        0.47473381,  0.82741616,  0.38715925,  0.82739681,  0.33295965,\n",
      "        0.82994944,  0.31998117,  0.83138715,  0.29459272,  0.83066821,\n",
      "        0.26656564,  0.83151614,  0.23889069,  0.83151614,  0.47473381,\n",
      "        0.82741616,  0.38715925,  0.82739681,  0.33295965,  0.82994944,\n",
      "        0.31998117,  0.83138715,  0.29459272,  0.83066821,  0.26656564,\n",
      "        0.83151614,  0.23889069,  0.83151614,  0.47473381,  0.82741616,\n",
      "        0.38715925,  0.82739681,  0.33295965,  0.82994944,  0.31998117,\n",
      "        0.83138715,  0.29459272,  0.83066821,  0.26656564,  0.83151614,\n",
      "        0.23889069,  0.83151614,  0.47166033,  0.82693856,  0.38443586,\n",
      "        0.82523915,  0.32856526,  0.82607319,  0.31782244,  0.82908182,\n",
      "        0.29298482,  0.83066821,  0.26695523,  0.83151614,  0.23732241,\n",
      "        0.83151614,  0.47453354,  0.82189655,  0.38590995,  0.82763454,\n",
      "        0.33823093,  0.82986638,  0.32221208,  0.83138715,  0.29384648,\n",
      "        0.83066821,  0.26922775,  0.83151614,  0.23792881,  0.83151614,\n",
      "        0.47453354,  0.82189655,  0.38590995,  0.82763454,  0.33823093,\n",
      "        0.82986638,  0.32221208,  0.83138715,  0.29384648,  0.83066821,\n",
      "        0.26922775,  0.83151614,  0.23792881,  0.83151614,  0.47453354,\n",
      "        0.82189655,  0.38590995,  0.82763454,  0.33823093,  0.82986638,\n",
      "        0.32221208,  0.83138715,  0.29384648,  0.83066821,  0.26922775,\n",
      "        0.83151614,  0.23792881,  0.83151614,  0.47700553,  0.82741616,\n",
      "        0.38664791,  0.82739681,  0.33564743,  0.82994944,  0.3218846 ,\n",
      "        0.83138715,  0.29148236,  0.83066821,  0.26636374,  0.83151614,\n",
      "        0.23603665,  0.83151614,  0.47700553,  0.82741616,  0.38664791,\n",
      "        0.82739681,  0.33564743,  0.82994944,  0.3218846 ,  0.83138715,\n",
      "        0.29148236,  0.83066821,  0.26636374,  0.83151614,  0.23603665,\n",
      "        0.83151614,  0.47700553,  0.82741616,  0.38664791,  0.82739681,\n",
      "        0.33564743,  0.82994944,  0.3218846 ,  0.83138715,  0.29148236,\n",
      "        0.83066821,  0.26636374,  0.83151614,  0.23603665,  0.83151614,\n",
      "        0.47700553,  0.82741616,  0.38664791,  0.82739681,  0.33564743,\n",
      "        0.82994944,  0.3218846 ,  0.83138715,  0.29148236,  0.83066821,\n",
      "        0.26636374,  0.83151614,  0.23603665,  0.83151614,  0.47596107,\n",
      "        0.82000569,  0.39715221,  0.82972099,  0.3369938 ,  0.8303664 ,\n",
      "        0.32669609,  0.8307739 ,  0.29103129,  0.83012951,  0.26690174,\n",
      "        0.83079733,  0.23859335,  0.83079733,  0.47596107,  0.82000569,\n",
      "        0.39715221,  0.82972099,  0.3369938 ,  0.8303664 ,  0.32669609,\n",
      "        0.8307739 ,  0.29103129,  0.83012951,  0.26690174,  0.83079733,\n",
      "        0.23859335,  0.83079733,  0.47596107,  0.82000569,  0.39715221,\n",
      "        0.82972099,  0.3369938 ,  0.8303664 ,  0.32669609,  0.8307739 ,\n",
      "        0.29103129,  0.83012951,  0.26690174,  0.83079733,  0.23859335,\n",
      "        0.83079733,  0.47596107,  0.82000569,  0.39715221,  0.82972099,\n",
      "        0.3369938 ,  0.8303664 ,  0.32669609,  0.8307739 ,  0.29103129,\n",
      "        0.83012951,  0.26690174,  0.83079733,  0.23859335,  0.83079733,\n",
      "        0.47596107,  0.82000569,  0.39715221,  0.82972099,  0.3369938 ,\n",
      "        0.8303664 ,  0.32669609,  0.8307739 ,  0.29103129,  0.83012951,\n",
      "        0.26690174,  0.83079733,  0.23859335,  0.83079733,  0.47596107,\n",
      "        0.82000569,  0.39715221,  0.82972099,  0.3369938 ,  0.8303664 ,\n",
      "        0.32669609,  0.8307739 ,  0.29103129,  0.83012951,  0.26690174,\n",
      "        0.83079733,  0.23859335,  0.83079733,  0.47596107,  0.82000569,\n",
      "        0.39715221,  0.82972099,  0.3369938 ,  0.8303664 ,  0.32669609,\n",
      "        0.8307739 ,  0.29103129,  0.83012951,  0.26690174,  0.83079733,\n",
      "        0.23859335,  0.83079733,  0.47596107,  0.82000569,  0.39715221,\n",
      "        0.82972099,  0.3369938 ,  0.8303664 ,  0.32669609,  0.8307739 ,\n",
      "        0.29103129,  0.83012951,  0.26690174,  0.83079733,  0.23859335,\n",
      "        0.83079733]), 'mean_train_score': array([ 0.46182146,  0.81832533,  0.36865175,  0.81872036,  0.32915374,\n",
      "        0.82005348,  0.30891553,  0.82086407,  0.28967701,  0.82260612,\n",
      "        0.26259541,  0.82326789,  0.24176436,  0.82326789,  0.45490022,\n",
      "        0.81458805,  0.36908787,  0.81918917,  0.33327417,  0.8213252 ,\n",
      "        0.30969377,  0.82163252,  0.28768577,  0.82262017,  0.26292685,\n",
      "        0.82326789,  0.24213945,  0.82326789,  0.45490022,  0.81458805,\n",
      "        0.36908787,  0.81918917,  0.33327417,  0.8213252 ,  0.30969377,\n",
      "        0.82163252,  0.28768577,  0.82262017,  0.26292685,  0.82326789,\n",
      "        0.24213945,  0.82326789,  0.45490022,  0.81458805,  0.36908787,\n",
      "        0.81918917,  0.33327417,  0.8213252 ,  0.30969377,  0.82163252,\n",
      "        0.28768577,  0.82262017,  0.26292685,  0.82326789,  0.24213945,\n",
      "        0.82326789,  0.45751184,  0.81666532,  0.36905926,  0.81907405,\n",
      "        0.32962359,  0.82111157,  0.30933941,  0.82158647,  0.28972979,\n",
      "        0.82262017,  0.26286411,  0.82326789,  0.24149368,  0.82326789,\n",
      "        0.45751184,  0.81666532,  0.36905926,  0.81907405,  0.32962359,\n",
      "        0.82111157,  0.30933941,  0.82158647,  0.28972979,  0.82262017,\n",
      "        0.26286411,  0.82326789,  0.24149368,  0.82326789,  0.45751184,\n",
      "        0.81666532,  0.36905926,  0.81907405,  0.32962359,  0.82111157,\n",
      "        0.30933941,  0.82158647,  0.28972979,  0.82262017,  0.26286411,\n",
      "        0.82326789,  0.24149368,  0.82326789,  0.45751184,  0.81666532,\n",
      "        0.36905926,  0.81907405,  0.32962359,  0.82111157,  0.30933941,\n",
      "        0.82158647,  0.28972979,  0.82262017,  0.26286411,  0.82326789,\n",
      "        0.24149368,  0.82326789,  0.45687064,  0.81832533,  0.36895898,\n",
      "        0.81872036,  0.3290372 ,  0.82005348,  0.30860212,  0.82086407,\n",
      "        0.28929322,  0.82260612,  0.26239326,  0.82326789,  0.24080783,\n",
      "        0.82326789,  0.45772433,  0.81458805,  0.37073415,  0.81918917,\n",
      "        0.33111957,  0.8213252 ,  0.31019082,  0.82163252,  0.28875217,\n",
      "        0.82262017,  0.26320708,  0.82326789,  0.2416253 ,  0.82326789,\n",
      "        0.45772433,  0.81458805,  0.37073415,  0.81918917,  0.33111957,\n",
      "        0.8213252 ,  0.31019082,  0.82163252,  0.28875217,  0.82262017,\n",
      "        0.26320708,  0.82326789,  0.2416253 ,  0.82326789,  0.45772433,\n",
      "        0.81458805,  0.37073415,  0.81918917,  0.33111957,  0.8213252 ,\n",
      "        0.31019082,  0.82163252,  0.28875217,  0.82262017,  0.26320708,\n",
      "        0.82326789,  0.2416253 ,  0.82326789,  0.45829125,  0.81666532,\n",
      "        0.37116227,  0.81907405,  0.33194486,  0.82111157,  0.31095553,\n",
      "        0.82158647,  0.28914548,  0.82262017,  0.26187221,  0.82326789,\n",
      "        0.2404087 ,  0.82326789,  0.45829125,  0.81666532,  0.37116227,\n",
      "        0.81907405,  0.33194486,  0.82111157,  0.31095553,  0.82158647,\n",
      "        0.28914548,  0.82262017,  0.26187221,  0.82326789,  0.2404087 ,\n",
      "        0.82326789,  0.45829125,  0.81666532,  0.37116227,  0.81907405,\n",
      "        0.33194486,  0.82111157,  0.31095553,  0.82158647,  0.28914548,\n",
      "        0.82262017,  0.26187221,  0.82326789,  0.2404087 ,  0.82326789,\n",
      "        0.45829125,  0.81666532,  0.37116227,  0.81907405,  0.33194486,\n",
      "        0.82111157,  0.31095553,  0.82158647,  0.28914548,  0.82262017,\n",
      "        0.26187221,  0.82326789,  0.2404087 ,  0.82326789,  0.45889339,\n",
      "        0.81284595,  0.37518082,  0.8216774 ,  0.33618198,  0.82211727,\n",
      "        0.31691349,  0.82253743,  0.29152504,  0.8227631 ,  0.26281249,\n",
      "        0.82302175,  0.241538  ,  0.82302175,  0.45889339,  0.81284595,\n",
      "        0.37518082,  0.8216774 ,  0.33618198,  0.82211727,  0.31691349,\n",
      "        0.82253743,  0.29152504,  0.8227631 ,  0.26281249,  0.82302175,\n",
      "        0.241538  ,  0.82302175,  0.45889339,  0.81284595,  0.37518082,\n",
      "        0.8216774 ,  0.33618198,  0.82211727,  0.31691349,  0.82253743,\n",
      "        0.29152504,  0.8227631 ,  0.26281249,  0.82302175,  0.241538  ,\n",
      "        0.82302175,  0.45889339,  0.81284595,  0.37518082,  0.8216774 ,\n",
      "        0.33618198,  0.82211727,  0.31691349,  0.82253743,  0.29152504,\n",
      "        0.8227631 ,  0.26281249,  0.82302175,  0.241538  ,  0.82302175,\n",
      "        0.45889339,  0.81284595,  0.37518082,  0.8216774 ,  0.33618198,\n",
      "        0.82211727,  0.31691349,  0.82253743,  0.29152504,  0.8227631 ,\n",
      "        0.26281249,  0.82302175,  0.241538  ,  0.82302175,  0.45889339,\n",
      "        0.81284595,  0.37518082,  0.8216774 ,  0.33618198,  0.82211727,\n",
      "        0.31691349,  0.82253743,  0.29152504,  0.8227631 ,  0.26281249,\n",
      "        0.82302175,  0.241538  ,  0.82302175,  0.45889339,  0.81284595,\n",
      "        0.37518082,  0.8216774 ,  0.33618198,  0.82211727,  0.31691349,\n",
      "        0.82253743,  0.29152504,  0.8227631 ,  0.26281249,  0.82302175,\n",
      "        0.241538  ,  0.82302175,  0.45889339,  0.81284595,  0.37518082,\n",
      "        0.8216774 ,  0.33618198,  0.82211727,  0.31691349,  0.82253743,\n",
      "        0.29152504,  0.8227631 ,  0.26281249,  0.82302175,  0.241538  ,\n",
      "        0.82302175]), 'std_train_score': array([ 0.00933118,  0.00769002,  0.01419818,  0.00493981,  0.00400086,\n",
      "        0.00455451,  0.00637457,  0.00598129,  0.00757684,  0.00620273,\n",
      "        0.01407162,  0.00649562,  0.01652138,  0.00649562,  0.01100957,\n",
      "        0.00560737,  0.01673799,  0.00689085,  0.00555154,  0.00625541,\n",
      "        0.00850181,  0.00704177,  0.00617541,  0.00618682,  0.01602723,\n",
      "        0.00649562,  0.01653189,  0.00649562,  0.01100957,  0.00560737,\n",
      "        0.01673799,  0.00689085,  0.00555154,  0.00625541,  0.00850181,\n",
      "        0.00704177,  0.00617541,  0.00618682,  0.01602723,  0.00649562,\n",
      "        0.01653189,  0.00649562,  0.01100957,  0.00560737,  0.01673799,\n",
      "        0.00689085,  0.00555154,  0.00625541,  0.00850181,  0.00704177,\n",
      "        0.00617541,  0.00618682,  0.01602723,  0.00649562,  0.01653189,\n",
      "        0.00649562,  0.01261278,  0.0078323 ,  0.01280028,  0.00679379,\n",
      "        0.00419275,  0.00639004,  0.00851134,  0.00706258,  0.00578142,\n",
      "        0.00618682,  0.0149513 ,  0.00649562,  0.01697129,  0.00649562,\n",
      "        0.01261278,  0.0078323 ,  0.01280028,  0.00679379,  0.00419275,\n",
      "        0.00639004,  0.00851134,  0.00706258,  0.00578142,  0.00618682,\n",
      "        0.0149513 ,  0.00649562,  0.01697129,  0.00649562,  0.01261278,\n",
      "        0.0078323 ,  0.01280028,  0.00679379,  0.00419275,  0.00639004,\n",
      "        0.00851134,  0.00706258,  0.00578142,  0.00618682,  0.0149513 ,\n",
      "        0.00649562,  0.01697129,  0.00649562,  0.01261278,  0.0078323 ,\n",
      "        0.01280028,  0.00679379,  0.00419275,  0.00639004,  0.00851134,\n",
      "        0.00706258,  0.00578142,  0.00618682,  0.0149513 ,  0.00649562,\n",
      "        0.01697129,  0.00649562,  0.0104593 ,  0.00769002,  0.01192671,\n",
      "        0.00493981,  0.00140201,  0.00455451,  0.00851213,  0.00598129,\n",
      "        0.00756798,  0.00620273,  0.01386294,  0.00649562,  0.01822959,\n",
      "        0.00649562,  0.01233781,  0.00560737,  0.01079154,  0.00689085,\n",
      "        0.00627563,  0.00625541,  0.00866591,  0.00704177,  0.00640963,\n",
      "        0.00618682,  0.01558909,  0.00649562,  0.01685479,  0.00649562,\n",
      "        0.01233781,  0.00560737,  0.01079154,  0.00689085,  0.00627563,\n",
      "        0.00625541,  0.00866591,  0.00704177,  0.00640963,  0.00618682,\n",
      "        0.01558909,  0.00649562,  0.01685479,  0.00649562,  0.01233781,\n",
      "        0.00560737,  0.01079154,  0.00689085,  0.00627563,  0.00625541,\n",
      "        0.00866591,  0.00704177,  0.00640963,  0.00618682,  0.01558909,\n",
      "        0.00649562,  0.01685479,  0.00649562,  0.01357828,  0.0078323 ,\n",
      "        0.01096377,  0.00679379,  0.00483787,  0.00639004,  0.00800521,\n",
      "        0.00706258,  0.00653159,  0.00618682,  0.01555098,  0.00649562,\n",
      "        0.01621232,  0.00649562,  0.01357828,  0.0078323 ,  0.01096377,\n",
      "        0.00679379,  0.00483787,  0.00639004,  0.00800521,  0.00706258,\n",
      "        0.00653159,  0.00618682,  0.01555098,  0.00649562,  0.01621232,\n",
      "        0.00649562,  0.01357828,  0.0078323 ,  0.01096377,  0.00679379,\n",
      "        0.00483787,  0.00639004,  0.00800521,  0.00706258,  0.00653159,\n",
      "        0.00618682,  0.01555098,  0.00649562,  0.01621232,  0.00649562,\n",
      "        0.01357828,  0.0078323 ,  0.01096377,  0.00679379,  0.00483787,\n",
      "        0.00639004,  0.00800521,  0.00706258,  0.00653159,  0.00618682,\n",
      "        0.01555098,  0.00649562,  0.01621232,  0.00649562,  0.01207112,\n",
      "        0.00578996,  0.01603343,  0.00619319,  0.00603483,  0.00620511,\n",
      "        0.0100194 ,  0.00662254,  0.01040954,  0.00595954,  0.0149274 ,\n",
      "        0.00619358,  0.01729492,  0.00619358,  0.01207112,  0.00578996,\n",
      "        0.01603343,  0.00619319,  0.00603483,  0.00620511,  0.0100194 ,\n",
      "        0.00662254,  0.01040954,  0.00595954,  0.0149274 ,  0.00619358,\n",
      "        0.01729492,  0.00619358,  0.01207112,  0.00578996,  0.01603343,\n",
      "        0.00619319,  0.00603483,  0.00620511,  0.0100194 ,  0.00662254,\n",
      "        0.01040954,  0.00595954,  0.0149274 ,  0.00619358,  0.01729492,\n",
      "        0.00619358,  0.01207112,  0.00578996,  0.01603343,  0.00619319,\n",
      "        0.00603483,  0.00620511,  0.0100194 ,  0.00662254,  0.01040954,\n",
      "        0.00595954,  0.0149274 ,  0.00619358,  0.01729492,  0.00619358,\n",
      "        0.01207112,  0.00578996,  0.01603343,  0.00619319,  0.00603483,\n",
      "        0.00620511,  0.0100194 ,  0.00662254,  0.01040954,  0.00595954,\n",
      "        0.0149274 ,  0.00619358,  0.01729492,  0.00619358,  0.01207112,\n",
      "        0.00578996,  0.01603343,  0.00619319,  0.00603483,  0.00620511,\n",
      "        0.0100194 ,  0.00662254,  0.01040954,  0.00595954,  0.0149274 ,\n",
      "        0.00619358,  0.01729492,  0.00619358,  0.01207112,  0.00578996,\n",
      "        0.01603343,  0.00619319,  0.00603483,  0.00620511,  0.0100194 ,\n",
      "        0.00662254,  0.01040954,  0.00595954,  0.0149274 ,  0.00619358,\n",
      "        0.01729492,  0.00619358,  0.01207112,  0.00578996,  0.01603343,\n",
      "        0.00619319,  0.00603483,  0.00620511,  0.0100194 ,  0.00662254,\n",
      "        0.01040954,  0.00595954,  0.0149274 ,  0.00619358,  0.01729492,\n",
      "        0.00619358])}\n"
     ]
    }
   ],
   "source": [
    "print(imputer_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.224969240658\n",
      "{'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 10, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "print(imputer_cv.best_score_)\n",
    "print(imputer_cv.best_params_)\n",
    "params = imputer_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='brute', leaf_size=10, metric='minkowski',\n",
       "          metric_params=None, n_jobs=-1, n_neighbors=10, p=2,\n",
       "          weights='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a model using the best parameters\n",
    "imputer = KNeighborsRegressor(n_neighbors=params['n_neighbors'], weights=params['weights'], \n",
    "                              algorithm=params['algorithm'], leaf_size=params['leaf_size'], \n",
    "                              p=2, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "imputer.fit(data_ohe.loc[~data_ohe.isnull().any(axis=1),['SibSp', 'Parch', 'Fare', 'Survived', 'Pclass_1', 'Pclass_2',\n",
    "       'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q',\n",
    "       'Embarked_S']],\n",
    "               data_ohe.loc[~data_ohe.isnull().any(axis=1),'Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict the age values\n",
    "age_predictions = imputer.predict(data_ohe.loc[data_ohe.isnull().any(axis=1),['SibSp', 'Parch', 'Fare', 'Survived', 'Pclass_1', 'Pclass_2',\n",
    "       'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q',\n",
    "       'Embarked_S']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the missing values with the predicted values\n",
    "data_ohe.loc[data_ohe.loc[:,'Age'].isnull(),'Age'] = age_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event rate:  38.38\n"
     ]
    }
   ],
   "source": [
    "# check the event rate\n",
    "print('Event rate: ', round((data_ohe.loc[:,'Survived'].sum()/data_ohe.shape[0])*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age           0\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Fare          0\n",
      "Survived      0\n",
      "Pclass_1      0\n",
      "Pclass_2      0\n",
      "Pclass_3      0\n",
      "Sex_female    0\n",
      "Sex_male      0\n",
      "Embarked_C    0\n",
      "Embarked_Q    0\n",
      "Embarked_S    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check number of missing values\n",
    "print(data_ohe.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 16)\n",
      "    Age  SibSp  Parch      Fare  Survived  Pclass_1  Pclass_2  Pclass_3  \\\n",
      "0  22.0  0.125    0.0  0.014151         0         0         0         1   \n",
      "1  38.0  0.125    0.0  0.139136         1         1         0         0   \n",
      "2  26.0  0.000    0.0  0.015469         1         0         0         1   \n",
      "3  35.0  0.125    0.0  0.103644         1         1         0         0   \n",
      "4  35.0  0.000    0.0  0.015713         0         0         0         1   \n",
      "\n",
      "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S         Sex  \\\n",
      "0           0         1           0           0           1    Sex_male   \n",
      "1           1         0           1           0           0  Sex_female   \n",
      "2           1         0           0           0           1  Sex_female   \n",
      "3           1         0           0           0           1  Sex_female   \n",
      "4           0         1           0           0           1    Sex_male   \n",
      "\n",
      "     Embarked    Pclass  \n",
      "0  Embarked_S  Pclass_3  \n",
      "1  Embarked_C  Pclass_1  \n",
      "2  Embarked_S  Pclass_3  \n",
      "3  Embarked_S  Pclass_1  \n",
      "4  Embarked_S  Pclass_3  \n"
     ]
    }
   ],
   "source": [
    "# reverse the dummy creation\n",
    "data_ohe.loc[:,'Sex'] = data_ohe.loc[:,['Sex_male','Sex_female']].idxmax(axis=1)\n",
    "data_ohe.loc[:,'Embarked'] = data_ohe.loc[:,['Embarked_C','Embarked_Q','Embarked_S']].idxmax(axis=1)\n",
    "data_ohe.loc[:,'Pclass'] = data_ohe.loc[:,['Pclass_1','Pclass_2','Pclass_3']].idxmax(axis=1)\n",
    "print(data_ohe.shape)\n",
    "print(data_ohe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 8)\n"
     ]
    }
   ],
   "source": [
    "# drop the dummy columns\n",
    "data_ohe.drop(['Sex_male','Sex_female','Embarked_C','Embarked_Q','Embarked_S','Pclass_1','Pclass_2','Pclass_3'],inplace=True,axis=1)\n",
    "print(data_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Survived    0\n",
       "Sex         0\n",
       "Embarked    0\n",
       "Pclass      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ohe.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Embarked_S', 'Embarked_C', 'Embarked_Q'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ohe.loc[:,'Embarked'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_mvt = data_ohe.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(823, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "data_mvt.dtypes\n",
    "numeric_columns = ['Age','SibSp','Parch','Fare']\n",
    "data_mvt[(np.abs(stats.zscore(data_mvt.loc[:,numeric_columns])) < 3).all(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop the outlier\n",
    "data_ot = data_mvt[(np.abs(stats.zscore(data_mvt.loc[:,numeric_columns])) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event rate:  38.88\n"
     ]
    }
   ],
   "source": [
    "# check the event rate\n",
    "print('Event rate: ', round((data_ot.loc[:,'Survived'].sum()/data_ot.shape[0])*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(823, 8)\n",
      "    Age  SibSp  Parch      Fare  Survived         Sex    Embarked    Pclass\n",
      "0  22.0  0.125    0.0  0.014151         0    Sex_male  Embarked_S  Pclass_3\n",
      "1  38.0  0.125    0.0  0.139136         1  Sex_female  Embarked_C  Pclass_1\n",
      "2  26.0  0.000    0.0  0.015469         1  Sex_female  Embarked_S  Pclass_3\n",
      "3  35.0  0.125    0.0  0.103644         1  Sex_female  Embarked_S  Pclass_1\n",
      "4  35.0  0.000    0.0  0.015713         0    Sex_male  Embarked_S  Pclass_3\n"
     ]
    }
   ],
   "source": [
    "print(data_ot.shape)\n",
    "print(data_ot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the data\n",
    "data_ot.to_csv('titanic_survivors_preprocessed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('titanic_survivors_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(823, 8)\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Survived    0\n",
      "Sex         0\n",
      "Embarked    0\n",
      "Pclass      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'SibSp', 'Parch', 'Fare', 'Survived', 'Sex', 'Embarked',\n",
      "       'Pclass'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange the columns\n",
    "data = data.loc[:,['Age', 'SibSp', 'Parch', 'Fare', 'Sex', 'Embarked','Pclass','Survived']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Building a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will build a logistic model and tune its parameters using grid search cross validation. But first we need to encode the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "for col in data.loc[:,['Age', 'SibSp', 'Parch', 'Fare', 'Sex', 'Embarked','Pclass','Survived']].columns.values:\n",
    "    # Encoding only categorical variables\n",
    "    if data.loc[:,col].dtypes=='object':\n",
    "        le.fit(data.loc[:,col].values)\n",
    "        data.loc[:,col]=le.transform(data.loc[:,col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(823, 8)\n",
      "    Age  SibSp  Parch      Fare  Sex  Embarked  Pclass  Survived\n",
      "0  22.0  0.125    0.0  0.014151    1         2       2         0\n",
      "1  38.0  0.125    0.0  0.139136    0         0       0         1\n",
      "2  26.0  0.000    0.0  0.015469    0         2       2         1\n",
      "3  35.0  0.125    0.0  0.103644    0         2       0         1\n",
      "4  35.0  0.000    0.0  0.015713    1         2       2         0\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=1, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([  0.1    ,   0.62105,   1.14211,   1.66316,   2.18421,   2.70526,\n",
       "         3.22632,   3.74737,   4.26842,   4.78947,   5.31053,   5.83158,\n",
       "         6.35263,   6.87368,   7.39474,   7.91579,   8.43684,   8.95789,\n",
       "         9.47895,  10.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "lr = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
    "                        intercept_scaling=1, class_weight=None, random_state=42, \n",
    "                        solver='liblinear', max_iter=100, multi_class='ovr', \n",
    "                        verbose=1, warm_start=False, n_jobs=1)\n",
    "param_grid={\n",
    "    'C': np.linspace(0.1,10,20)\n",
    "}\n",
    "\n",
    "lr_cv = GridSearchCV(lr,param_grid, cv=5,verbose=True)\n",
    "lr_cv.fit(data.iloc[:,0:7],data.iloc[:,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797083839611\n",
      "{'C': 0.62105263157894741}\n"
     ]
    }
   ],
   "source": [
    "print(lr_cv.best_score_)\n",
    "print(lr_cv.best_params_)\n",
    "params_lr = lr_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.62105263157894741, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a model with the best params\n",
    "lr = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=params_lr['C'], fit_intercept=True, \n",
    "                        intercept_scaling=1, class_weight=None, random_state=None, \n",
    "                        solver='liblinear', max_iter=100, multi_class='ovr', \n",
    "                        verbose=1, warm_start=False, n_jobs=1)\n",
    "nrows = int(0.7*data.shape[0])\n",
    "lr.fit(data.iloc[0:nrows,0:7],data.iloc[0:nrows,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will assess the performance of the model using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions\n",
    "predictions = lr.predict(data.iloc[nrows:,0:7])\n",
    "true_values = data.iloc[nrows:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Died       0.81      0.90      0.85       160\n",
      "   Survived       0.77      0.61      0.68        87\n",
      "\n",
      "avg / total       0.79      0.80      0.79       247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\n",
    "target_names=['Died', 'Survived']\n",
    "print(classification_report(true_values, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to plot confusion matrix\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        1#print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(823,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(y_pred_score_log))\n",
    "y_pred_score_log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC:  0.856537356322\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCQpJQoREUlKiUJERJL6f/6SIDy5fxOnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ce9dda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEmCAYAAACDLjAiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cfbcc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the confusion matrix\n",
    "cnf_matrix_lr = confusion_matrix(true_values, predictions)\n",
    "class_names = ['Legitimate','Fraud']\n",
    "\n",
    "# plot the AUC ROC curve\n",
    "y_pred_score_log = lr.decision_function(data.iloc[nrows:,0:7])\n",
    "fpr_log, tpr_log, thresholds = roc_curve(true_values, y_pred_score_log)\n",
    "roc_auc_log = auc(fpr_log,tpr_log)\n",
    "print('AUC ROC: ',roc_auc_log)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_log, tpr_log, 'b',label='AUC = %0.3f'% roc_auc_log)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "plot_confusion_matrix(cnf_matrix_lr, classes=class_names, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.drop(['PassengerId','Ticket','Name','Cabin'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 7)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 12)\n"
     ]
    }
   ],
   "source": [
    "# knn requires all data to be numerical. We will convert Pclass, Sex and Embarked to dummy encoded variables\n",
    "dm_test_pclass = pd.get_dummies(test.loc[:,'Pclass'],prefix='Pclass')\n",
    "dm_test_sex = pd.get_dummies(test.loc[:,'Sex'],prefix='Sex')\n",
    "dm_test_embarked = pd.get_dummies(test.loc[:,'Embarked'],prefix='Embarked')\n",
    "\n",
    "test_ohe = pd.concat([test, dm_test_pclass, dm_test_sex, dm_test_embarked], axis=1)\n",
    "test_ohe.drop(['Pclass','Sex','Embarked'],inplace=True,axis=1)\n",
    "print(test_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age           86\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           1\n",
      "Pclass_1       0\n",
      "Pclass_2       0\n",
      "Pclass_3       0\n",
      "Sex_female     0\n",
      "Sex_male       0\n",
      "Embarked_C     0\n",
      "Embarked_Q     0\n",
      "Embarked_S     0\n",
      "dtype: int64\n",
      "[332 418 418 417 418 418 418 418 418 418 418 418]\n",
      "[418 418 418 418 418 418 418 418 418 418 418 418]\n",
      "(418, 12)\n"
     ]
    }
   ],
   "source": [
    "# get missing value information\n",
    "import numpy as np\n",
    "print(test_ohe.isnull().sum(axis=0))\n",
    "print(np.isfinite(test_ohe.values).sum(axis=0))\n",
    "print((np.isfinite(test_ohe.values) | np.isnan(test_ohe.values)).sum(axis=0))\n",
    "print(test_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max=MinMaxScaler()\n",
    "test_ohe.loc[np.logical_not(test_ohe.isnull().any(axis=1)),['SibSp', 'Parch', 'Fare']] = min_max.fit_transform(test_ohe.loc[np.logical_not(test_ohe.isnull().any(axis=1)),['SibSp', 'Parch', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-b1e8f9062a9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m new_age_predictions = imputer.predict(test_ohe.loc[test_ohe.isnull().any(axis=1),['SibSp', 'Parch', 'Fare', 'Survived', 'Pclass_1', 'Pclass_2',\n\u001b[1;32m      3\u001b[0m        \u001b[0;34m'Pclass_3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sex_female'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sex_male'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Embarked_C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Embarked_Q'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m        'Embarked_S']])\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/neighbors/regression.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mTarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \"\"\"\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    420\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     41\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     42\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 43\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# new predictions\n",
    "new_age_predictions = imputer.predict(test_ohe.loc[test_ohe.isnull().any(axis=1),['SibSp', 'Parch', 'Fare', 'Survived', 'Pclass_1', 'Pclass_2',\n",
    "       'Pclass_3', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q',\n",
    "       'Embarked_S']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
